{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9782e83-a236-4516-8ae6-a61a20739e4c",
   "metadata": {},
   "source": [
    "# mini-MIAS data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f87c57f-04da-4104-b587-27154793d181",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T12:19:40.419096Z",
     "start_time": "2025-08-21T12:19:39.567819Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|███████████████████████████████████████████████████████████████| 83/83 [00:05<00:00, 16.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training set: (92, 1024, 1024), (92,)\n",
      "Augmented training set: (233, 1024, 1024), (233,)\n",
      "Validation set: (23, 1024, 1024), (23,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from scipy import ndimage\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "\n",
    "class MammogramPreprocessor:\n",
    "    def __init__(self, image_dir, metadata_path, output_dir, img_size=(1024, 1024)):\n",
    "        \"\"\"\n",
    "        Initialize the mammogram preprocessor.\n",
    "        \n",
    "        Args:\n",
    "            image_dir: Directory containing the mini-MIAS images\n",
    "            metadata_path: Path to the CSV file with metadata\n",
    "            output_dir: Directory to save processed images\n",
    "            img_size: Target size for the processed images\n",
    "        \"\"\"\n",
    "        self.image_dir = image_dir\n",
    "        self.metadata_path = metadata_path\n",
    "        self.output_dir = output_dir\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        # Create output directories if they don't exist\n",
    "        os.makedirs(os.path.join(output_dir, \"processed_images\"), exist_ok=True)\n",
    "        os.makedirs(os.path.join(output_dir, \"roi_images\"), exist_ok=True)\n",
    "        \n",
    "        # Load metadata\n",
    "        self.metadata = pd.read_csv(metadata_path)\n",
    "        \n",
    "        # Create a dictionary for quick lookup of image metadata\n",
    "        self.image_metadata = {}\n",
    "        for _, row in self.metadata.iterrows():\n",
    "            ref_num = row['REFNUM']\n",
    "            if ref_num not in self.image_metadata:\n",
    "                self.image_metadata[ref_num] = []\n",
    "            \n",
    "            # Only add entries with abnormalities (those with coordinates)\n",
    "            if not pd.isna(row['X']) and not pd.isna(row['Y']) and not pd.isna(row['RADIUS']):\n",
    "                self.image_metadata[ref_num].append({\n",
    "                    'x': int(row['X']),\n",
    "                    'y': int(row['Y']),\n",
    "                    'radius': int(row['RADIUS']),\n",
    "                    'class': row['CLASS'],\n",
    "                    'severity': row['SEVERITY'] if not pd.isna(row['SEVERITY']) else None,\n",
    "                    'bg': row['BG']  # Breast density type\n",
    "                })\n",
    "    \n",
    "    def load_image(self, image_path):\n",
    "        \"\"\"Load an image and convert to grayscale if needed.\"\"\"\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Could not load image: {image_path}\")\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    def remove_background(self, img):\n",
    "        \"\"\"Extract breast region mask without altering breast pixel values.\"\"\"\n",
    "        \n",
    "        # Ensure grayscale\n",
    "        if len(img.shape) == 3:\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = img.copy()\n",
    "        \n",
    "        # Keep a clean version of grayscale to use later\n",
    "        original_gray = gray.copy()\n",
    "        \n",
    "        # Use filtered version only for mask creation\n",
    "        eq = cv2.equalizeHist(gray)\n",
    "        blurred = cv2.GaussianBlur(eq, (5, 5), 0)\n",
    "        \n",
    "        _, binary = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        \n",
    "        # Invert if necessary\n",
    "        if np.sum(binary == 255) > np.sum(binary == 0):\n",
    "            binary = cv2.bitwise_not(binary)\n",
    "        \n",
    "        # Morphological cleanup\n",
    "        kernel = np.ones((15, 15), np.uint8)\n",
    "        binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
    "        binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "        \n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Create mask from largest contour (breast region)\n",
    "        mask = np.zeros_like(gray)\n",
    "        if contours:\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "            cv2.drawContours(mask, [largest_contour], 0, 255, -1)\n",
    "            \n",
    "            # Dilate slightly to cover edges\n",
    "            mask = cv2.dilate(mask, np.ones((3, 3), np.uint8), iterations=1)\n",
    "            \n",
    "            # Apply mask to original grayscale\n",
    "            result = cv2.bitwise_and(original_gray, original_gray, mask=mask)\n",
    "            return result, mask\n",
    "        \n",
    "        # If no contours found, return the original image and a full mask\n",
    "        return original_gray, np.ones_like(gray) * 255\n",
    "    \n",
    "    def remove_pectoral_muscle(self, img, mask=None):\n",
    "        \"\"\"\n",
    "        Remove the pectoral muscle from the mammogram with extremely aggressive removal.\n",
    "        \n",
    "        This implementation prioritizes complete removal of the pectoral muscle,\n",
    "        particularly for images with larger pectoral regions.\n",
    "        \n",
    "        Args:\n",
    "            img: Input mammogram image\n",
    "            mask: Optional breast region mask\n",
    "            \n",
    "        Returns:\n",
    "            Image with pectoral muscle removed\n",
    "        \"\"\"\n",
    "        if img is None:\n",
    "            return None\n",
    "        \n",
    "        # Create a copy of the image\n",
    "        result = img.copy()\n",
    "        height, width = img.shape\n",
    "        \n",
    "        # Determine if the breast is on the left or right side\n",
    "        if mask is None:\n",
    "            # Create a simple mask if none is provided\n",
    "            _, simple_mask = cv2.threshold(img, 5, 255, cv2.THRESH_BINARY)\n",
    "            mask = simple_mask\n",
    "        \n",
    "        left_sum = np.sum(mask[:, :mask.shape[1]//2])\n",
    "        right_sum = np.sum(mask[:, mask.shape[1]//2:])\n",
    "        is_left_breast = left_sum > right_sum\n",
    "        \n",
    "        try:\n",
    "            # Step 1: Define a very large region of interest for pectoral muscle\n",
    "            # Use a much larger portion of the image to ensure we capture the entire pectoral muscle\n",
    "            pectoral_height = int(height * 0.85)  # Increased from 0.6 to 0.7\n",
    "            pectoral_width = int(width * 0.65)    # Increased from 0.4 to 0.5\n",
    "            \n",
    "            # Extract the pectoral muscle region\n",
    "            if is_left_breast:\n",
    "                pectoral_region = img[0:pectoral_height, 0:pectoral_width]\n",
    "                x_offset, y_offset = 0, 0\n",
    "            else:\n",
    "                pectoral_region = img[0:pectoral_height, width-pectoral_width:width]\n",
    "                x_offset, y_offset = width-pectoral_width, 0\n",
    "            \n",
    "            # Check if pectoral region is valid\n",
    "            if pectoral_region.size == 0 or np.max(pectoral_region) == 0:\n",
    "                return img  # Return original image if pectoral region is invalid\n",
    "            \n",
    "            # Step 2: Create a very aggressive triangular mask\n",
    "            # This is our primary approach - a geometric mask that covers the typical pectoral region\n",
    "            pectoral_mask = np.zeros_like(pectoral_region)\n",
    "            \n",
    "            # Calculate the slope for the triangular mask based on image dimensions\n",
    "            # This creates an extremely aggressive triangle that covers more of the pectoral region\n",
    "            if is_left_breast:\n",
    "                # For left breast, create a triangle from top-left corner\n",
    "                # Use a much more aggressive slope\n",
    "                for y in range(pectoral_height):\n",
    "                    # Quadratic function for more aggressive coverage at the top\n",
    "                    width_at_y = int(pectoral_width * (1 - (y / pectoral_height)))\n",
    "                    pectoral_mask[y, 0:width_at_y] = 255\n",
    "            else:\n",
    "                # For right breast, create a triangle from top-right corner\n",
    "                for y in range(pectoral_height):\n",
    "                    # Quadratic function for more aggressive coverage at the top\n",
    "                    width_at_y = int(pectoral_width * (1 - (y / pectoral_height)))\n",
    "                    pectoral_mask[y, pectoral_width-width_at_y:pectoral_width] = 255\n",
    "            \n",
    "            # Step 3: Apply morphological operations to ensure complete coverage\n",
    "            kernel = np.ones((5, 5), np.uint8)  # Much larger kernel for aggressive morphology\n",
    "            pectoral_mask = cv2.morphologyEx(pectoral_mask, cv2.MORPH_DILATE, kernel)\n",
    "            \n",
    "            # Step 4: Create a full-sized mask\n",
    "            full_mask = np.zeros_like(img)\n",
    "            full_mask[y_offset:y_offset+pectoral_height, x_offset:x_offset+pectoral_width] = pectoral_mask\n",
    "            \n",
    "            # Step 5: Apply a straight line boundary for a clean edge\n",
    "            # Instead of detecting the edge, we'll create a straight line from top to bottom\n",
    "            # This ensures a consistent, clean removal\n",
    "            \n",
    "            # Define the line parameters based on breast orientation\n",
    "            if is_left_breast:\n",
    "                top_x = int(width * 0.5)     # Increase from 0.25 to 0.35 or 0.4\n",
    "                bottom_x = int(width * 0.1)  # Increase from 0.05 to 0.08\n",
    "            else:\n",
    "                top_x = int(width * 0.55)     # Decrease from 0.75 to 0.65 or 0.6\n",
    "                bottom_x = int(width * 0.9)  # Decrease from 0.95 to 0.92\n",
    "            \n",
    "            # Create a refined mask with the straight line\n",
    "            refined_mask = np.zeros_like(img)\n",
    "            \n",
    "            # Draw the line and fill the appropriate side\n",
    "            for y in range(height):\n",
    "                # Linear interpolation between top_x and bottom_x\n",
    "                x_line = int(top_x + (bottom_x - top_x) * (y / height))\n",
    "                \n",
    "                if is_left_breast:\n",
    "                    x_range = range(0, min(x_line, width))\n",
    "                else:\n",
    "                    x_range = range(max(0, x_line), width)\n",
    "                \n",
    "                for x in x_range:\n",
    "                    refined_mask[y, x] = 255\n",
    "            \n",
    "            # Step 6: Combine the triangular mask with the straight line mask\n",
    "            # Use the most aggressive of the two approaches\n",
    "            combined_mask = cv2.bitwise_or(full_mask, refined_mask)\n",
    "            \n",
    "            # Invert the mask to keep everything except the pectoral muscle\n",
    "            final_mask = cv2.bitwise_not(combined_mask)\n",
    "            \n",
    "            # Step 7: Apply the mask to the original image\n",
    "            result = cv2.bitwise_and(img, img, mask=final_mask)\n",
    "            \n",
    "            # Step 8: Post-processing for smooth transition\n",
    "            # Create a gradient mask for the boundary\n",
    "            gradient_mask = cv2.GaussianBlur(final_mask, (31, 31), 0)  # Very large blur for smoother transition\n",
    "            \n",
    "            # Apply the gradient mask for smooth transition\n",
    "            result = cv2.bitwise_and(img, img, mask=gradient_mask)\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in pectoral muscle removal: {e}\")\n",
    "            # Return the original image if any error occurs\n",
    "            return img\n",
    "\n",
    "\n",
    "    \n",
    "    def enhance_contrast(self, img):\n",
    "        \"\"\"\n",
    "        Enhance image contrast using adaptive CLAHE,\n",
    "        tuned for low-contrast mammograms (like mini-MIAS).\n",
    "        \"\"\"\n",
    "        if img.dtype != np.uint8:\n",
    "            img = (img * 255).astype(np.uint8)  # Normalize before CLAHE if needed\n",
    "    \n",
    "        # Adaptive CLAHE parameters\n",
    "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(16, 16))  # Slightly higher clipLimit and tile size\n",
    "    \n",
    "        enhanced = clahe.apply(img)\n",
    "        return enhanced\n",
    "\n",
    "    \n",
    "    def extract_roi(self, img, x, y, radius, padding=10):\n",
    "        \"\"\"Extract a region of interest around a suspicious area.\"\"\"\n",
    "        # Add padding to the radius\n",
    "        padded_radius = radius + padding\n",
    "        \n",
    "        # Calculate the bounding box\n",
    "        x1 = max(0, x - padded_radius)\n",
    "        y1 = max(0, y - padded_radius)\n",
    "        x2 = min(img.shape[1], x + padded_radius)\n",
    "        y2 = min(img.shape[0], y + padded_radius)\n",
    "        \n",
    "        # Extract the ROI\n",
    "        roi = img[y1:y2, x1:x2]\n",
    "        \n",
    "        # Resize the ROI to the target size\n",
    "        roi_resized = cv2.resize(roi, self.img_size)\n",
    "        \n",
    "        return roi_resized\n",
    "    \n",
    "    def normalize_image(self, img):\n",
    "        \"\"\"\n",
    "        Normalize image to [0, 1] range, ensuring robustness.\n",
    "        \"\"\"\n",
    "        img = img.astype(np.float32)\n",
    "        \n",
    "        # Normalize only if max > 0\n",
    "        max_val = np.max(img)\n",
    "        if max_val > 0:\n",
    "            img /= max_val\n",
    "        return img\n",
    "\n",
    "    \n",
    "    \n",
    "    def process_image(self, image_path, save=True):\n",
    "        \"\"\"Process a single mammogram image with pectoral removal first.\"\"\"\n",
    "        # Extract the image reference number from the filename\n",
    "        filename = os.path.basename(image_path)\n",
    "        ref_num = os.path.splitext(filename)[0]\n",
    "        \n",
    "        # Load the image\n",
    "        original_img = self.load_image(image_path)\n",
    "        \n",
    "        # Remove background\n",
    "        img_no_bg, mask = self.remove_background(original_img)\n",
    "        \n",
    "        # Remove pectoral muscle\n",
    "        img_no_pectoral = self.remove_pectoral_muscle(img_no_bg, mask)\n",
    "        \n",
    "        \n",
    "        # Enhance contrast\n",
    "        img_enhanced = self.enhance_contrast(img_no_pectoral)\n",
    "        \n",
    "        # Normalize the image\n",
    "        img_normalized = self.normalize_image(img_enhanced)\n",
    "        \n",
    "        # Resize the image to the target size\n",
    "        img_resized = cv2.resize(img_enhanced, self.img_size)\n",
    "        \n",
    "        # Save the processed image\n",
    "        if save:\n",
    "            output_path = os.path.join(self.output_dir, \"processed_images\", f\"{ref_num}_processed.png\")\n",
    "            cv2.imwrite(output_path, img_resized)\n",
    "        # Extract ROIs if abnormalities exist\n",
    "        rois = []\n",
    "        if ref_num in self.image_metadata and self.image_metadata[ref_num]:\n",
    "            for abnormality in self.image_metadata[ref_num]:\n",
    "                x, y, radius = abnormality['x'], abnormality['y'], abnormality['radius']\n",
    "                roi = self.extract_roi(img_enhanced, x, y, radius)\n",
    "                \n",
    "                if save:\n",
    "                    roi_path = os.path.join(self.output_dir, \"roi_images\", \n",
    "                                           f\"{ref_num}_roi_x{x}_y{y}_r{radius}.png\")\n",
    "                    cv2.imwrite(roi_path, roi)\n",
    "                \n",
    "                rois.append({\n",
    "                    'roi': roi,\n",
    "                    'metadata': abnormality\n",
    "                })\n",
    "        \n",
    "        return {\n",
    "            'ref_num': ref_num,\n",
    "            'processed_image': img_resized,\n",
    "            'rois': rois,\n",
    "            'has_abnormality': len(rois) > 0\n",
    "        }\n",
    "\n",
    "    \n",
    "    def process_all_images(self):\n",
    "        \"\"\"Process all images in the dataset.\"\"\"\n",
    "        image_paths = glob.glob(os.path.join(self.image_dir, \"*.png\"))\n",
    "        if not image_paths:\n",
    "            image_paths = glob.glob(os.path.join(self.image_dir, \"*.pgm\"))\n",
    "        \n",
    "        results = []\n",
    "        for image_path in tqdm(image_paths, desc=\"Processing images\"):\n",
    "            try:\n",
    "                result = self.process_image(image_path)\n",
    "                results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {image_path}: {e}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def create_dataset(self):\n",
    "        \"\"\"Create a dataset for training a CNN.\"\"\"\n",
    "        processed_data = self.process_all_images()\n",
    "        \n",
    "        # Separate normal and abnormal cases\n",
    "        normal_cases = [data for data in processed_data if not data['has_abnormality']]\n",
    "        abnormal_cases = [data for data in processed_data if data['has_abnormality']]\n",
    "        \n",
    "        # Create X (images) and y (labels)\n",
    "        X = []\n",
    "        y = []\n",
    "        \n",
    "        # Add normal cases\n",
    "        for case in normal_cases:\n",
    "            X.append(case['processed_image'])\n",
    "            y.append(0)  # 0 for normal\n",
    "        \n",
    "        # Add abnormal cases\n",
    "        for case in abnormal_cases:\n",
    "            X.append(case['processed_image'])\n",
    "            y.append(1)  # 1 for abnormal\n",
    "            \n",
    "            # Also add ROIs as separate samples\n",
    "            for roi_data in case['rois']:\n",
    "                X.append(roi_data['roi'])\n",
    "                # If you want to differentiate between benign and malignant:\n",
    "                if roi_data['metadata']['severity'] == 'M':\n",
    "                    y.append(2)  # 2 for malignant\n",
    "                else:\n",
    "                    y.append(1)  # 1 for benign\n",
    "        \n",
    "        # Convert to numpy arrays\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        # Split into training and validation sets\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        return X_train, X_val, y_train, y_val\n",
    "    \n",
    "    def visualize_preprocessing(self, image_path):\n",
    "        \"\"\"Visualize the preprocessing steps for a single image.\"\"\"\n",
    "        # Load the image\n",
    "        original_img = self.load_image(image_path)\n",
    "        \n",
    "        # Remove background\n",
    "        img_no_bg, mask = self.remove_background(original_img)\n",
    "        \n",
    "        # Remove pectoral muscle\n",
    "        img_no_pectoral = self.remove_pectoral_muscle(img_no_bg, mask)\n",
    "        \n",
    "        \n",
    "        # Enhance contrast\n",
    "        img_enhanced = self.enhance_contrast(img_no_pectoral)\n",
    "        \n",
    "        # Create a figure to display the preprocessing steps\n",
    "        fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "        \n",
    "        axes[0].imshow(original_img, cmap='gray')\n",
    "        axes[0].set_title('Original Image')\n",
    "        \n",
    "        axes[1].imshow(img_no_bg, cmap='gray')\n",
    "        axes[1].set_title('Background Removed')\n",
    "        \n",
    "        axes[2].imshow(img_no_pectoral, cmap='gray')\n",
    "        axes[2].set_title('Pectoral Muscle Removed')\n",
    "        \n",
    "        axes[4].imshow(img_enhanced, cmap='gray')\n",
    "        axes[4].set_title('Contrast Enhanced')\n",
    "        \n",
    "        for ax in axes:\n",
    "            ax.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Extract the image reference number from the filename\n",
    "        filename = os.path.basename(image_path)\n",
    "        ref_num = os.path.splitext(filename)[0]\n",
    "        \n",
    "        # Visualize ROIs if abnormalities exist\n",
    "        if ref_num in self.image_metadata and self.image_metadata[ref_num]:\n",
    "            fig, axes = plt.subplots(1, len(self.image_metadata[ref_num]), figsize=(4*len(self.image_metadata[ref_num]), 4))\n",
    "            \n",
    "            # Handle the case where there's only one abnormality\n",
    "            if len(self.image_metadata[ref_num]) == 1:\n",
    "                axes = [axes]\n",
    "            \n",
    "            for i, abnormality in enumerate(self.image_metadata[ref_num]):\n",
    "                x, y, radius = abnormality['x'], abnormality['y'], abnormality['radius']\n",
    "                roi = self.extract_roi(img_enhanced, x, y, radius)\n",
    "                \n",
    "                axes[i].imshow(roi, cmap='gray')\n",
    "                axes[i].set_title(f\"ROI: {abnormality['class']} ({abnormality['severity']})\")\n",
    "                axes[i].axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "def data_augmentation(X_train, y_train, augmentation_factor=2):\n",
    "    \"\"\"\n",
    "    Apply data augmentation to the training set.\n",
    "    \n",
    "    Args:\n",
    "        X_train: Training images\n",
    "        y_train: Training labels\n",
    "        augmentation_factor: How many times to augment the dataset\n",
    "        \n",
    "    Returns:\n",
    "        Augmented training set\n",
    "    \"\"\"\n",
    "    X_augmented = []\n",
    "    y_augmented = []\n",
    "    \n",
    "    # Add original data\n",
    "    X_augmented.extend(X_train)\n",
    "    y_augmented.extend(y_train)\n",
    "    \n",
    "    for i in range(len(X_train)):\n",
    "        img = X_train[i]\n",
    "        label = y_train[i]\n",
    "        \n",
    "        # Only augment abnormal cases (label > 0) more extensively\n",
    "        aug_factor = augmentation_factor if label > 0 else 1\n",
    "        \n",
    "        for _ in range(aug_factor):\n",
    "            # Randomly choose augmentation techniques\n",
    "            augmentation_type = np.random.choice(['flip', 'rotate', 'zoom', 'noise'])\n",
    "            \n",
    "            if augmentation_type == 'flip':\n",
    "                # Horizontal flip\n",
    "                augmented_img = cv2.flip(img, 1)\n",
    "            \n",
    "            elif augmentation_type == 'rotate':\n",
    "                # Random rotation between -15 and 15 degrees\n",
    "                angle = np.random.uniform(-15, 15)\n",
    "                augmented_img = ndimage.rotate(img, angle, reshape=False)\n",
    "            \n",
    "            elif augmentation_type == 'zoom':\n",
    "                # Random zoom between 0.9 and 1.1\n",
    "                zoom_factor = np.random.uniform(0.9, 1.1)\n",
    "                h, w = img.shape[:2]\n",
    "                \n",
    "                # Calculate new dimensions\n",
    "                new_h, new_w = int(h * zoom_factor), int(w * zoom_factor)\n",
    "                \n",
    "                # Resize the image\n",
    "                if zoom_factor < 1.0:  # Zoom out\n",
    "                    augmented_img = cv2.resize(img, (new_w, new_h))\n",
    "                    # Pad to original size\n",
    "                    pad_h = (h - new_h) // 2\n",
    "                    pad_w = (w - new_w) // 2\n",
    "                    augmented_img = cv2.copyMakeBorder(\n",
    "                        augmented_img, pad_h, h - new_h - pad_h, pad_w, w - new_w - pad_w,\n",
    "                        cv2.BORDER_CONSTANT, value=0\n",
    "                    )\n",
    "                else:  # Zoom in\n",
    "                    # Crop the center\n",
    "                    start_h = (h - new_h) // 2\n",
    "                    start_w = (w - new_w) // 2\n",
    "                    end_h = start_h + new_h\n",
    "                    end_w = start_w + new_w\n",
    "                    cropped = img[max(0, start_h):min(h, end_h), max(0, start_w):min(w, end_w)]\n",
    "                    augmented_img = cv2.resize(cropped, (w, h))\n",
    "            \n",
    "            elif augmentation_type == 'noise':\n",
    "                # Add Gaussian noise\n",
    "                mean = 0\n",
    "                stddev = np.random.uniform(0.01, 0.05)\n",
    "                noise = np.random.normal(mean, stddev, img.shape).astype(np.float32)\n",
    "                augmented_img = np.clip(img + noise, 0, 1).astype(np.float32)\n",
    "            \n",
    "            X_augmented.append(augmented_img)\n",
    "            y_augmented.append(label)\n",
    "    \n",
    "    return np.array(X_augmented), np.array(y_augmented)\n",
    "\n",
    "# Define paths\n",
    "image_dir = \"C:/Users/DragosTrandafiri/BreastCancer_CNN/data/raw/mini_mias/MIAS_pectoral\" \n",
    "metadata_path = \"C:/Users/DragosTrandafiri/BreastCancer_CNN/data/raw/mini_mias/mias_info.csv\"  \n",
    "output_dir = \"C:/Users/DragosTrandafiri/BreastCancer_CNN/data/processed/mini_mias_pectoral\"\n",
    "\n",
    "# Create preprocessor\n",
    "preprocessor = MammogramPreprocessor(image_dir, metadata_path, output_dir)\n",
    "\n",
    "# Visualize preprocessing for a sample image\n",
    "# sample_image_path = os.path.join(image_dir, \"mdb015.png\")  # Replace with an actual image path\n",
    "# preprocessor.visualize_preprocessing(sample_image_path)\n",
    "\n",
    "# Create dataset\n",
    "X_train, X_val, y_train, y_val = preprocessor.create_dataset()\n",
    "\n",
    "# Apply data augmentation\n",
    "X_train_aug, y_train_aug = data_augmentation(X_train, y_train)\n",
    "\n",
    "print(f\"Original training set: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Augmented training set: {X_train_aug.shape}, {y_train_aug.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}, {y_val.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0cd6783-d279-4165-9098-3139d1a32bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (from opencv-python) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (2.1.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (3.10.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (1.6.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (4.67.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (1.15.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install numpy pandas matplotlib scikit-learn tqdm scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be603c2-b0f2-4fc1-856b-b2bb0fe169ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
