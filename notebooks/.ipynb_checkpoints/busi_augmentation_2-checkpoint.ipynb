{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edfe27a1-914d-4277-8a5b-4a9cc897f49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbb2ce56-770c-4472-a59d-aca9776d37a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the notebook to load all its classes and functions\n",
    "%run busi_preprocessing_1.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af49443-0b3a-4f14-9ff5-9e88e87bf498",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c7ac15-b4e1-4271-8f94-683919d2c8c3",
   "metadata": {},
   "source": [
    "## Augmentation Details\n",
    "\n",
    "1. Per-class augmentation factor:\n",
    "\n",
    "Normal (label=0): 5x augmentation\n",
    "\n",
    "Malignant (label=2): 3x augmentation\n",
    "\n",
    "Benign (label=1): 1x augmentation\n",
    "\n",
    "2. Augmentation types:\n",
    "\n",
    "flip: Horizontal flip\n",
    "\n",
    "rotate: Random rotation between -15° and 15°\n",
    "\n",
    "zoom: Random zoom in/out (0.9–1.1 scale), with padding or cropping\n",
    "\n",
    "noise: Gaussian noise addition\n",
    "\n",
    "brightness: Random brightness adjustment (0.9–1.1 factor)\n",
    "\n",
    "3. Mask handling:\n",
    "\n",
    "If masks are provided, corresponding augmentations are applied identically to the mask.\n",
    "\n",
    "Masks maintain binary/segmentation structure (except for zoom, rotation, or flip).\n",
    "\n",
    "4. Channel dimension handling:\n",
    "\n",
    "Images and masks with a single channel (shape[-1]=1) are correctly expanded after augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae95f7cb-a443-4017-8254-b7a3b0bd5db5",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b61058a-bd7c-433b-8973-d0f687cae17a",
   "metadata": {},
   "source": [
    "Returns X_augmented, y_augmented, mask_augmented , if masks are provided, else X_augmented, y_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c54acbf-a561-4c28-ac36-2f0058271682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(X, y, masks=None):\n",
    "    \"\"\"\n",
    "    Apply data augmentation to the training set (supports optional masks).\n",
    "    \n",
    "    Args:\n",
    "        X_train: Training images\n",
    "        y_train: Training labels (0=Normal, 1=Benign, 2=Malignant)\n",
    "        masks: Optional masks (None if classification only)\n",
    "        \n",
    "    Returns:\n",
    "        Augmented images, labels, (and masks if provided)\n",
    "    \"\"\"\n",
    "    X_augmented, y_augmented = [], []\n",
    "    mask_augmented = [] if masks is not None else None\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        img = X[i]\n",
    "        label = y[i]\n",
    "        mask = masks[i] if masks is not None else None\n",
    "\n",
    "        # Define per-class augmentation strength\n",
    "        if label == 0:   # Normal (minority)\n",
    "            aug_factor = 5\n",
    "        elif label == 2: # Malignant (mid-size)\n",
    "            aug_factor = 3\n",
    "        else:            # Benign (majority)\n",
    "            aug_factor = 1\n",
    "\n",
    "        # Always keep original\n",
    "        X_augmented.append(img)\n",
    "        y_augmented.append(label)\n",
    "        if mask is not None:\n",
    "            mask_augmented.append(mask)\n",
    "\n",
    "        # Augmentations\n",
    "        for _ in range(aug_factor):\n",
    "            aug_type = np.random.choice(['flip', 'rotate', 'zoom', 'noise', 'brightness'])\n",
    "\n",
    "            img_2d = img.squeeze(-1) if img.ndim == 3 and img.shape[-1] == 1 else img\n",
    "            mask_2d = mask.squeeze(-1) if (mask is not None and mask.ndim == 3 and mask.shape[-1] == 1) else mask\n",
    "\n",
    "            if aug_type == 'flip':\n",
    "                aug_img = cv2.flip(img_2d, 1)\n",
    "                aug_mask = cv2.flip(mask_2d, 1) if mask is not None else None\n",
    "\n",
    "            elif aug_type == 'rotate':\n",
    "                angle = np.random.uniform(-15, 15)\n",
    "                aug_img = ndimage.rotate(img_2d, angle, reshape=False)\n",
    "                aug_mask = ndimage.rotate(mask_2d, angle, reshape=False) if mask is not None else None\n",
    "\n",
    "            elif aug_type == 'zoom':\n",
    "                zoom_factor = np.random.uniform(0.9, 1.1)\n",
    "                h, w = img_2d.shape\n",
    "                new_h, new_w = int(h * zoom_factor), int(w * zoom_factor)\n",
    "                aug_img = cv2.resize(img_2d, (new_w, new_h))\n",
    "                aug_mask = cv2.resize(mask_2d, (new_w, new_h)) if mask is not None else None\n",
    "\n",
    "                if zoom_factor < 1.0:  # pad\n",
    "                    pad_h = (h - new_h) // 2\n",
    "                    pad_w = (w - new_w) // 2\n",
    "                    aug_img = cv2.copyMakeBorder(aug_img, pad_h, h - new_h - pad_h,\n",
    "                                                 pad_w, w - new_w - pad_w,\n",
    "                                                 cv2.BORDER_CONSTANT, value=0)\n",
    "                    if mask is not None:\n",
    "                        aug_mask = cv2.copyMakeBorder(aug_mask, pad_h, h - new_h - pad_h,\n",
    "                                                      pad_w, w - new_w - pad_w,\n",
    "                                                      cv2.BORDER_CONSTANT, value=0)\n",
    "                else:  # crop\n",
    "                    start_h = (new_h - h) // 2\n",
    "                    start_w = (new_w - w) // 2\n",
    "                    aug_img = aug_img[start_h:start_h + h, start_w:start_w + w]\n",
    "                    if mask is not None:\n",
    "                        aug_mask = aug_mask[start_h:start_h + h, start_w:start_w + w]\n",
    "\n",
    "            elif aug_type == 'noise':\n",
    "                noise = np.random.normal(0, np.random.uniform(3, 8), img_2d.shape)\n",
    "                aug_img = np.clip(img_2d.astype(np.float32) + noise, 0, 255).astype(np.uint8)\n",
    "                aug_mask = mask_2d\n",
    "\n",
    "            elif aug_type == 'brightness':\n",
    "                factor = np.random.uniform(0.9, 1.1)\n",
    "                aug_img = np.clip(img_2d.astype(np.float32) * factor, 0, 255).astype(np.uint8)\n",
    "                aug_mask = mask_2d\n",
    "\n",
    "            # Restore channel dim\n",
    "            if img.ndim == 3 and img.shape[-1] == 1:\n",
    "                aug_img = np.expand_dims(aug_img, axis=-1)\n",
    "                if aug_mask is not None:\n",
    "                    aug_mask = np.expand_dims(aug_mask, axis=-1)\n",
    "\n",
    "            X_augmented.append(aug_img)\n",
    "            y_augmented.append(label)\n",
    "            if mask is not None:\n",
    "                mask_augmented.append(aug_mask)\n",
    "\n",
    "    if masks is not None:\n",
    "        return np.array(X_augmented), np.array(y_augmented), np.array(mask_augmented)\n",
    "    else:\n",
    "        return np.array(X_augmented), np.array(y_augmented)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f3e50c-0af3-4351-93e0-a785af19e369",
   "metadata": {},
   "source": [
    "# Apply data augmentation & creation of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0193b9f-3f28-4b77-9ac7-27e8db272e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 210 images and 211 masks in malignant folder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing malignant images: 100%|███████████████████████████████████████████████████| 210/210 [00:02<00:00, 87.28it/s]\n",
      "Processing malignant masks: 100%|███████████████████████████████████████████████████| 211/211 [00:00<00:00, 505.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 133 images and 133 masks in normal folder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing normal images: 100%|██████████████████████████████████████████████████████| 133/133 [00:01<00:00, 86.41it/s]\n",
      "Processing normal masks: 100%|██████████████████████████████████████████████████████| 133/133 [00:00<00:00, 244.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 437 images and 454 masks in benign folder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing benign images: 100%|██████████████████████████████████████████████████████| 437/437 [00:04<00:00, 91.38it/s]\n",
      "Processing benign masks: 100%|██████████████████████████████████████████████████████| 454/454 [00:00<00:00, 467.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined 2 masks for malignant (53).png\n",
      "Combined 2 masks for benign (100).png\n",
      "Combined 2 masks for benign (163).png\n",
      "Combined 2 masks for benign (173).png\n",
      "Combined 2 masks for benign (181).png\n",
      "Combined 3 masks for benign (195).png\n",
      "Combined 2 masks for benign (25).png\n",
      "Combined 2 masks for benign (315).png\n",
      "Combined 2 masks for benign (346).png\n",
      "Combined 2 masks for benign (4).png\n",
      "Combined 2 masks for benign (424).png\n",
      "Combined 2 masks for benign (54).png\n",
      "Combined 2 masks for benign (58).png\n",
      "Combined 2 masks for benign (83).png\n",
      "Combined 2 masks for benign (92).png\n",
      "Combined 2 masks for benign (93).png\n",
      "Combined 2 masks for benign (98).png\n",
      "Dataset shape: (780, 224, 224, 1)\n",
      "Masks shape: (780, 224, 224, 1)\n",
      "Labels shape: (780,)\n",
      "Class distribution: Normal: 133, Benign: 437, Malignant: 210\n",
      "Training set sizes: (546, 224, 224, 1), (546,), masks: (780, 224, 224, 1)\n",
      "Augmented training set sizes: (1758, 224, 224, 1), (1758,), masks: (1758, 224, 224, 1)\n",
      "Validation set sizes: (117, 224, 224, 1), (117,), masks: (117, 224, 224, 1)\n",
      "Test set sizes: (117, 224, 224, 1), (117,), masks: (117, 224, 224, 1)\n",
      "Augmented Normal: 558 samples\n",
      "Augmented Benign: 612 samples\n",
      "Augmented Malignant: 588 samples\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"C:/Users/DragosTrandafiri/BreastCancer_CNN/data/raw/busi\"   # benign, malignant, normal folders\n",
    "output_dir = \"C:/Users/DragosTrandafiri/BreastCancer_CNN/data/processed/busi\"\n",
    "\n",
    "# Create preprocessor\n",
    "preprocessor = BUSIPreprocessor(data_dir, output_dir, img_size=(224, 224))\n",
    "\n",
    "#for class_name in ['malignant', 'normal', 'benign']:\n",
    "# Create dataset\n",
    "X, y, masks = preprocessor.create_dataset()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#First split -> train + temp (val + test)\n",
    "X_train, X_temp, y_train, y_temp, masks_train, masks_temp = train_test_split(\n",
    "    X, y, masks,\n",
    "    test_size=0.3,  # 30% goes to val + test\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Split temp -> val + test\n",
    "X_val, X_test, y_val, y_test, masks_val, masks_test = train_test_split(\n",
    "    X_temp, y_temp, masks_temp,\n",
    "    test_size=0.5,  # Half of 30% → 15% val, 15% test\n",
    "    stratify=y_temp,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Apply data augmentation with masks\n",
    "X_aug, y_aug, masks_aug = data_augmentation(X_train, y_train, masks_train)\n",
    "\n",
    "print(f\"Training set sizes: X_train: {X_train.shape}, y_train: {y_train.shape}, masks: {masks.shape}\")\n",
    "print(f\"Augmented training set sizes: X_aug: {X_aug.shape}, y_aug: {y_aug.shape}, masks: {masks_aug.shape}\")\n",
    "print(f\"Validation set sizes: X_val: {X_val.shape}, y_val: {y_val.shape}, masks: {masks_val.shape}\")\n",
    "print(f\"Test set sizes: X_test: {X_test.shape}, y_test: {y_test.shape}, masks: {masks_test.shape}\")\n",
    "\n",
    "# Print class distribution\n",
    "unique, counts = np.unique(y_aug, return_counts=True)\n",
    "class_names = ['Normal', 'Benign', 'Malignant']\n",
    "for i, (class_idx, count) in enumerate(zip(unique, counts)):\n",
    "    print(f\"Augmented {class_names[class_idx]}: {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8c10733-974f-4563-a723-062ba5853961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented images saved to: C:/Users/DragosTrandafiri/BreastCancer_CNN/data/processed/busi/processed_images_augmented/X\n"
     ]
    }
   ],
   "source": [
    "# Define output directory for augmented images\n",
    "augmented_dir_X = \"C:/Users/DragosTrandafiri/BreastCancer_CNN/data/processed/busi/processed_images_augmented/X\"\n",
    "augmented_dir_Mask = \"C:/Users/DragosTrandafiri/BreastCancer_CNN/data/processed/busi/processed_images_augmented/Mask\"\n",
    "\n",
    "# Class names mapping\n",
    "class_names = ['Normal', 'Benign', 'Malignant']\n",
    "\n",
    "# Create directories if they don’t exist\n",
    "for class_name in class_names:\n",
    "    os.makedirs(os.path.join(augmented_dir_X, class_name), exist_ok=True)\n",
    "    os.makedirs(os.path.join(augmented_dir_Mask, class_name), exist_ok=True)\n",
    "\n",
    "# Save images\n",
    "for i, (img_X, img_Mask, label) in enumerate(zip(X_aug, masks_aug, y_aug)):\n",
    "    # Convert from float [0,1] to uint8 [0,255] if needed\n",
    "    if img_X.max() <= 1.0:\n",
    "        img_to_save_X = (img_X * 255).astype(np.uint8)\n",
    "    else:\n",
    "        img_to_save_X = img_X.astype(np.uint8)\n",
    "\n",
    "    if img_Mask.max() <= 1.0:\n",
    "        img_to_save_mask = (img_Mask * 255).astype(np.uint8)\n",
    "    else:\n",
    "        img_to_save_mask = img_Mask.astype(np.uint8)\n",
    "\n",
    "    # Ensure channel order is correct (OpenCV uses BGR)\n",
    "    if img_to_save_X.shape[-1] == 3:  \n",
    "        img_to_save_X = cv2.cvtColor(img_to_save_X, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    if img_to_save_mask.shape[-1] == 3:  \n",
    "        img_to_save_mask = cv2.cvtColor(img_to_save_mask, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "\n",
    "    # Build filename\n",
    "    filename = f\"aug_{i:05d}.png\"\n",
    "    filepath_x = os.path.join(augmented_dir_X, class_names[label], filename)\n",
    "\n",
    "    # Save\n",
    "    cv2.imwrite(filepath_x, img_to_save_X)\n",
    "\n",
    "\n",
    "    filename = f\"aug_mask_{i:05d}.png\"\n",
    "    filepath_mask = os.path.join(augmented_dir_Mask, class_names[label], filename)\n",
    "\n",
    "    # Save\n",
    "    cv2.imwrite(filepath_mask, img_to_save_mask)\n",
    "\n",
    "print(f\"Augmented images saved to: {augmented_dir_X}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0086b5d-96db-4b8a-8b11-bba9d8578851",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
