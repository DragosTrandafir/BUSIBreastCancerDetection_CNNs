{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9782e83-a236-4516-8ae6-a61a20739e4c",
   "metadata": {},
   "source": [
    "# mini-MIAS data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86664fa6-d1b4-4d5c-88f7-72881db92f4d",
   "metadata": {},
   "source": [
    "# Important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c70ea8b7-dc3a-4e2e-af1a-e2569f73ce8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from scipy import ndimage\n",
    "from sklearn.linear_model import RANSACRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92735747-5d32-458c-b564-3c7393fd19d5",
   "metadata": {},
   "source": [
    "# Preprocessing class with all needed functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f87c57f-04da-4104-b587-27154793d181",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T12:19:40.419096Z",
     "start_time": "2025-08-21T12:19:39.567819Z"
    }
   },
   "outputs": [],
   "source": [
    "class MammogramPreprocessor:\n",
    "    def __init__(self, image_dir, metadata_path, output_dir, img_size=(1024, 1024)):\n",
    "        \"\"\"\n",
    "        Initialize the mammogram preprocessor.\n",
    "        \n",
    "        Args:\n",
    "            image_dir: Directory containing the mini-MIAS images\n",
    "            metadata_path: Path to the CSV file with metadata\n",
    "            output_dir: Directory to save processed images\n",
    "            img_size: Target size for the processed images\n",
    "        \"\"\"\n",
    "        self.image_dir = image_dir\n",
    "        self.metadata_path = metadata_path\n",
    "        self.output_dir = output_dir\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        # Create output directories if they don't exist\n",
    "        os.makedirs(os.path.join(output_dir, \"processed_images\"), exist_ok=True)\n",
    "        os.makedirs(os.path.join(output_dir, \"roi_images\"), exist_ok=True)\n",
    "        \n",
    "        # Load metadata\n",
    "        self.metadata = pd.read_csv(metadata_path)\n",
    "        \n",
    "        # Create a dictionary for quick lookup of image metadata\n",
    "        self.image_metadata = {}\n",
    "        for _, row in self.metadata.iterrows():\n",
    "            ref_num = row['REFNUM']\n",
    "            if ref_num not in self.image_metadata:\n",
    "                self.image_metadata[ref_num] = []\n",
    "            \n",
    "            # Only add entries with abnormalities (those with coordinates)\n",
    "            if not pd.isna(row['X']) and not pd.isna(row['Y']) and not pd.isna(row['RADIUS']):\n",
    "                self.image_metadata[ref_num].append({\n",
    "                    'x': int(row['X']),\n",
    "                    'y': int(row['Y']),\n",
    "                    'radius': int(row['RADIUS']),\n",
    "                    'class': row['CLASS'],\n",
    "                    'severity': row['SEVERITY'] if not pd.isna(row['SEVERITY']) else None,\n",
    "                    'bg': row['BG']  # Breast density type\n",
    "                })\n",
    "\n",
    "    \n",
    "    # loading an image and grayscaling it if necessary\n",
    "    def load_image(self, image_path):\n",
    "        \"\"\"Load an image and convert to grayscale if needed.\"\"\"\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Could not load image: {image_path}\")\n",
    "        \n",
    "        return img\n",
    "\n",
    "\n",
    "    # Noise removal\n",
    "    # Background removal \n",
    "    def remove_background(self, img):\n",
    "        \"\"\"Extract breast region mask without altering breast pixel values.\"\"\"\n",
    "        \n",
    "        # Ensure grayscale\n",
    "        if len(img.shape) == 3:\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = img.copy()\n",
    "        \n",
    "        # Keep a clean version of grayscale to use later\n",
    "        original_gray = gray.copy()\n",
    "        \n",
    "        # Use filtered version only for mask creation\n",
    "        eq = cv2.equalizeHist(gray)\n",
    "        blurred = cv2.GaussianBlur(eq, (5, 5), 0)\n",
    "        \n",
    "        _, binary = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        \n",
    "        # Invert if necessary\n",
    "        if np.sum(binary == 255) > np.sum(binary == 0):\n",
    "            binary = cv2.bitwise_not(binary)\n",
    "        \n",
    "        # Morphological cleanup\n",
    "        kernel = np.ones((15, 15), np.uint8)\n",
    "        binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
    "        binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "        \n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Create mask from largest contour (breast region)\n",
    "        mask = np.zeros_like(gray)\n",
    "        if contours:\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "            cv2.drawContours(mask, [largest_contour], 0, 255, -1)\n",
    "            \n",
    "            # Dilate slightly to cover edges\n",
    "            mask = cv2.dilate(mask, np.ones((3, 3), np.uint8), iterations=1)\n",
    "            \n",
    "            # Apply mask to original grayscale\n",
    "            result = cv2.bitwise_and(original_gray, original_gray, mask=mask)\n",
    "            return result, mask\n",
    "        \n",
    "        # If no contours found, return the original image and a full mask\n",
    "        return original_gray, np.ones_like(gray) * 255\n",
    "\n",
    "    # Pectoral muscle removal\n",
    "    def remove_pectoral_muscle(self, img, mask=None):\n",
    "        \"\"\"\n",
    "        Remove the pectoral muscle from the mammogram with extremely aggressive removal.\n",
    "        \n",
    "        This implementation prioritizes complete removal of the pectoral muscle,\n",
    "        particularly for images with larger pectoral regions.\n",
    "        \n",
    "        Args:\n",
    "            img: Input mammogram image\n",
    "            mask: Optional breast region mask\n",
    "            \n",
    "        Returns:\n",
    "            Image with pectoral muscle removed\n",
    "        \"\"\"\n",
    "        if img is None:\n",
    "            return None\n",
    "        \n",
    "        # Create a copy of the image\n",
    "        result = img.copy()\n",
    "        height, width = img.shape\n",
    "        \n",
    "        # Determine if the breast is on the left or right side\n",
    "        if mask is None:\n",
    "            # Create a simple mask if none is provided\n",
    "            _, simple_mask = cv2.threshold(img, 5, 255, cv2.THRESH_BINARY)\n",
    "            mask = simple_mask\n",
    "        \n",
    "        left_sum = np.sum(mask[:, :mask.shape[1]//2])\n",
    "        right_sum = np.sum(mask[:, mask.shape[1]//2:])\n",
    "        is_left_breast = left_sum > right_sum\n",
    "        \n",
    "        try:\n",
    "            # Step 1: Define a very large region of interest for pectoral muscle\n",
    "            # Use a much larger portion of the image to ensure we capture the entire pectoral muscle\n",
    "            pectoral_height = int(height * 0.74)  # Increased from 0.6 to 0.7\n",
    "            pectoral_width = int(width * 0.54)    # Increased from 0.4 to 0.5\n",
    "            \n",
    "            # Extract the pectoral muscle region\n",
    "            if is_left_breast:\n",
    "                pectoral_region = img[0:pectoral_height, 0:pectoral_width]\n",
    "                x_offset, y_offset = 0, 0\n",
    "            else:\n",
    "                pectoral_region = img[0:pectoral_height, width-pectoral_width:width]\n",
    "                x_offset, y_offset = width-pectoral_width, 0\n",
    "            \n",
    "            # Check if pectoral region is valid\n",
    "            if pectoral_region.size == 0 or np.max(pectoral_region) == 0:\n",
    "                return img  # Return original image if pectoral region is invalid\n",
    "            \n",
    "            # Step 2: Create a very aggressive triangular mask\n",
    "            # This is our primary approach - a geometric mask that covers the typical pectoral region\n",
    "            pectoral_mask = np.zeros_like(pectoral_region)\n",
    "            \n",
    "            # Calculate the slope for the triangular mask based on image dimensions\n",
    "            # This creates an extremely aggressive triangle that covers more of the pectoral region\n",
    "            if is_left_breast:\n",
    "                # For left breast, create a triangle from top-left corner\n",
    "                # Use a much more aggressive slope\n",
    "                for y in range(pectoral_height):\n",
    "                    # Quadratic function for more aggressive coverage at the top\n",
    "                    width_at_y = int(pectoral_width * (1 - (y / pectoral_height)))\n",
    "                    pectoral_mask[y, 0:width_at_y] = 255\n",
    "            else:\n",
    "                # For right breast, create a triangle from top-right corner\n",
    "                for y in range(pectoral_height):\n",
    "                    # Quadratic function for more aggressive coverage at the top\n",
    "                    width_at_y = int(pectoral_width * (1 - (y / pectoral_height)))\n",
    "                    pectoral_mask[y, pectoral_width-width_at_y:pectoral_width] = 255\n",
    "            \n",
    "            # Step 3: Apply morphological operations to ensure complete coverage\n",
    "            kernel = np.ones((5, 5), np.uint8)  # Much larger kernel for aggressive morphology\n",
    "            pectoral_mask = cv2.morphologyEx(pectoral_mask, cv2.MORPH_DILATE, kernel)\n",
    "            \n",
    "            # Step 4: Create a full-sized mask\n",
    "            full_mask = np.zeros_like(img)\n",
    "            full_mask[y_offset:y_offset+pectoral_height, x_offset:x_offset+pectoral_width] = pectoral_mask\n",
    "            \n",
    "            # Step 5: Apply a straight line boundary for a clean edge\n",
    "            # Instead of detecting the edge, we'll create a straight line from top to bottom\n",
    "            # This ensures a consistent, clean removal\n",
    "            \n",
    "            # Define the line parameters based on breast orientation\n",
    "            if is_left_breast:\n",
    "                top_x = int(width * 0.36)     # Increase from 0.25 to 0.35 or 0.4\n",
    "                bottom_x = int(width * 0.08)  # Increase from 0.05 to 0.08\n",
    "            else:\n",
    "                top_x = int(width * 0.63)     # Decrease from 0.75 to 0.65 or 0.6\n",
    "                bottom_x = int(width * 0.91)  # Decrease from 0.95 to 0.92\n",
    "            \n",
    "            # Create a refined mask with the straight line\n",
    "            refined_mask = np.zeros_like(img)\n",
    "            \n",
    "            # Draw the line and fill the appropriate side\n",
    "            for y in range(height):\n",
    "                # Linear interpolation between top_x and bottom_x\n",
    "                x_line = int(top_x + (bottom_x - top_x) * (y / height))\n",
    "                \n",
    "                if is_left_breast:\n",
    "                    x_range = range(0, min(x_line, width))\n",
    "                else:\n",
    "                    x_range = range(max(0, x_line), width)\n",
    "                \n",
    "                for x in x_range:\n",
    "                    refined_mask[y, x] = 255\n",
    "            \n",
    "            # Step 6: Combine the triangular mask with the straight line mask\n",
    "            # Use the most aggressive of the two approaches\n",
    "            combined_mask = cv2.bitwise_or(full_mask, refined_mask)\n",
    "            \n",
    "            # Invert the mask to keep everything except the pectoral muscle\n",
    "            final_mask = cv2.bitwise_not(combined_mask)\n",
    "            \n",
    "            # Step 7: Apply the mask to the original image\n",
    "            result = cv2.bitwise_and(img, img, mask=final_mask)\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in pectoral muscle removal: {e}\")\n",
    "            # Return the original image if any error occurs\n",
    "            return img\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # Filters applied to the mini-MIAS images\n",
    "    def enhance_contrast(self, img):\n",
    "        \"\"\"\n",
    "        Enhance image contrast using adaptive CLAHE,\n",
    "        tuned for low-contrast mammograms (like mini-MIAS).\n",
    "        \"\"\"\n",
    "        if img.dtype != np.uint8:\n",
    "            img = (img * 255).astype(np.uint8)  # Normalize before CLAHE if needed\n",
    "    \n",
    "        # Adaptive CLAHE parameters\n",
    "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(16, 16))  # Slightly higher clipLimit and tile size\n",
    "    \n",
    "        enhanced = clahe.apply(img)\n",
    "        return enhanced\n",
    "\n",
    "    def normalize_image(self, img):\n",
    "        \"\"\"\n",
    "        Normalize image to [0, 1] range, ensuring robustness.\n",
    "        \"\"\"\n",
    "        img = img.astype(np.float32)\n",
    "        \n",
    "        # Normalize only if max > 0\n",
    "        max_val = np.max(img)\n",
    "        if max_val > 0:\n",
    "            img /= max_val\n",
    "        return img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Extract region of interest\n",
    "    def extract_roi(self, img, x, y, radius, padding=50):\n",
    "        \"\"\"Extract a region of interest around a suspicious area.\"\"\"\n",
    "        # Add padding to the radius\n",
    "        padded_radius = radius + padding\n",
    "        \n",
    "        # Calculate the bounding box\n",
    "        x1 = max(0, x - padded_radius)\n",
    "        y1 = max(0, y - padded_radius)\n",
    "        x2 = min(img.shape[1], x + padded_radius)\n",
    "        y2 = min(img.shape[0], y + padded_radius)\n",
    "        \n",
    "        # Extract the ROI\n",
    "        roi = img[y1:y2, x1:x2]\n",
    "        \n",
    "        # Resize the ROI to the target size\n",
    "        roi_resized = cv2.resize(roi, self.img_size)\n",
    "        \n",
    "        return roi_resized\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    # All steps in processing an image (the order is important for efficiency and reliability)\n",
    "    def process_image(self, image_path, save=True):\n",
    "        \"\"\"Process a single mammogram image with pectoral removal first.\"\"\"\n",
    "        # Extract the image reference number from the filename\n",
    "        filename = os.path.basename(image_path)\n",
    "        ref_num = os.path.splitext(filename)[0]\n",
    "        \n",
    "        # Load the image\n",
    "        original_img = self.load_image(image_path)\n",
    "\n",
    "\n",
    "        \n",
    "        # Remove background\n",
    "        img_no_bg, mask = self.remove_background(original_img)\n",
    "        \n",
    "        # Remove pectoral muscle\n",
    "        img_no_pectoral = self.remove_pectoral_muscle(img_no_bg, mask)\n",
    "\n",
    "        \n",
    "        \n",
    "        # Enhance contrast\n",
    "        img_enhanced = self.enhance_contrast(img_no_pectoral)\n",
    "        \n",
    "        # Normalize the image\n",
    "        img_normalized = self.normalize_image(img_enhanced)\n",
    "\n",
    "        \n",
    "        # Resize the image to the target size -> (224 x 224) -> smaller and better results for CNN approach\n",
    "        img_resized = cv2.resize(img_enhanced, self.img_size)\n",
    "        \n",
    "        # Save the processed image\n",
    "        if save:\n",
    "            output_path = os.path.join(self.output_dir, \"processed_images\", f\"{ref_num}_processed.png\")\n",
    "            cv2.imwrite(output_path, img_resized)\n",
    "            \n",
    "        # Extract ROIs if abnormalities exist\n",
    "        rois = []\n",
    "        if ref_num in self.image_metadata and self.image_metadata[ref_num]:\n",
    "            for abnormality in self.image_metadata[ref_num]:\n",
    "                x, y, radius = abnormality['x'], abnormality['y'], abnormality['radius']\n",
    "                roi = self.extract_roi(img_enhanced, x, y, radius)\n",
    "                \n",
    "                if save:\n",
    "                    roi_path = os.path.join(self.output_dir, \"roi_images\", \n",
    "                                           f\"{ref_num}_roi_x{x}_y{y}_r{radius}.png\")\n",
    "                    cv2.imwrite(roi_path, roi)\n",
    "                \n",
    "                rois.append({\n",
    "                    'roi': roi,\n",
    "                    'metadata': abnormality\n",
    "                })\n",
    "        \n",
    "        return {\n",
    "            'ref_num': ref_num,\n",
    "            'processed_image': img_resized,\n",
    "            'rois': rois,\n",
    "            'has_abnormality': len(rois) > 0\n",
    "        }\n",
    "\n",
    "    \n",
    "    def process_all_images(self):\n",
    "        \"\"\"Process all images in the dataset.\"\"\"\n",
    "        image_paths = glob.glob(os.path.join(self.image_dir, \"*.png\"))\n",
    "        if not image_paths:\n",
    "            image_paths = glob.glob(os.path.join(self.image_dir, \"*.pgm\"))\n",
    "        \n",
    "        results = []\n",
    "        for image_path in tqdm(image_paths, desc=\"Processing images\"):\n",
    "            try:\n",
    "                result = self.process_image(image_path)\n",
    "                results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {image_path}: {e}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def create_dataset(self):\n",
    "        \"\"\"Create a dataset for training a CNN with ROI masks included.\"\"\"\n",
    "        processed_data = self.process_all_images()\n",
    "    \n",
    "        X, y, masks = [], [], []\n",
    "    \n",
    "        for case in processed_data:\n",
    "            # Base processed image\n",
    "            X.append(case['processed_image'])\n",
    "            y.append(0 if not case['has_abnormality'] else 1)\n",
    "    \n",
    "            # For normal cases → no mask\n",
    "            if not case['has_abnormality']:\n",
    "                masks.append(np.zeros_like(case['processed_image'], dtype=np.uint8))\n",
    "            else:\n",
    "                # Build a mask with abnormalities\n",
    "                mask = np.zeros_like(case['processed_image'], dtype=np.uint8)\n",
    "                for roi_data in case['rois']:\n",
    "                    x, y_c, r = roi_data['metadata']['x'], roi_data['metadata']['y'], roi_data['metadata']['radius']\n",
    "                    # Scale coordinates if resized\n",
    "                    scale_x = self.img_size[0] / case['processed_image'].shape[1]\n",
    "                    scale_y = self.img_size[1] / case['processed_image'].shape[0]\n",
    "                    center = (int(x * scale_x), int(y_c * scale_y))\n",
    "                    radius = int(r * scale_x)  # assuming square pixels\n",
    "                    cv2.circle(mask, center, radius, 255, -1)\n",
    "                masks.append(mask)\n",
    "\n",
    "            # Also add ROI crops as extra training samples\n",
    "            for roi_data in case['rois']:\n",
    "                roi = roi_data['roi']\n",
    "                roi_mask = np.ones_like(roi, dtype=np.uint8) * 255  # ROI fully relevant\n",
    "                X.append(roi)\n",
    "                if roi_data['metadata']['severity'] == 'M':\n",
    "                    y.append(2)  # Malignant\n",
    "                else:\n",
    "                    y.append(1)  # Benign\n",
    "                masks.append(roi_mask)\n",
    "    \n",
    "        X, y, masks = np.array(X), np.array(y), np.array(masks)\n",
    "    \n",
    "        # Train-val split (keep masks aligned)\n",
    "        X_train, X_val, y_train, y_val, masks_train, masks_val = train_test_split(\n",
    "            X, y, masks, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "    \n",
    "        return X_train, X_val, y_train, y_val, masks_train, masks_val\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee3530d2-edb3-4529-9345-baac9e6f4c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(X_train, y_train, masks=None):\n",
    "    \"\"\"\n",
    "    Apply data augmentation to images (and masks if provided).\n",
    "    Masks are binary (0/255).\n",
    "    \"\"\"\n",
    "    X_augmented, y_augmented = [], []\n",
    "    mask_augmented = [] if masks is not None else None\n",
    "\n",
    "    for i in range(len(X_train)):\n",
    "        img, label = X_train[i], y_train[i]\n",
    "        mask = masks[i] if masks is not None else None\n",
    "\n",
    "        # Define per-class augmentation factor\n",
    "        if label == 0:\n",
    "            aug_factor = 4\n",
    "        elif label == 2:\n",
    "            aug_factor = 3\n",
    "        else:\n",
    "            aug_factor = 1\n",
    "\n",
    "        # Keep original\n",
    "        X_augmented.append(img)\n",
    "        y_augmented.append(label)\n",
    "        if mask is not None:\n",
    "            mask_augmented.append(mask)\n",
    "\n",
    "        # Apply augmentations\n",
    "        for _ in range(aug_factor):\n",
    "            aug_type = np.random.choice(['flip', 'rotate', 'zoom', 'noise', 'brightness'])\n",
    "            img_2d = img.copy()\n",
    "            mask_2d = mask.copy() if mask is not None else None\n",
    "\n",
    "            if aug_type == 'flip':\n",
    "                aug_img = cv2.flip(img_2d, 1)\n",
    "                aug_mask = cv2.flip(mask_2d, 1) if mask is not None else None\n",
    "\n",
    "            elif aug_type == 'rotate':\n",
    "                angle = np.random.uniform(-15, 15)\n",
    "                aug_img = ndimage.rotate(img_2d, angle, reshape=False)\n",
    "                aug_mask = ndimage.rotate(mask_2d, angle, reshape=False) if mask is not None else None\n",
    "\n",
    "            elif aug_type == 'zoom':\n",
    "                zoom_factor = np.random.uniform(0.9, 1.1)\n",
    "                h, w = img_2d.shape[:2]\n",
    "                new_h, new_w = int(h * zoom_factor), int(w * zoom_factor)\n",
    "                aug_img = cv2.resize(img_2d, (new_w, new_h))\n",
    "                aug_mask = cv2.resize(mask_2d, (new_w, new_h), interpolation=cv2.INTER_NEAREST) if mask is not None else None\n",
    "\n",
    "                # Crop/pad to original size\n",
    "                if zoom_factor < 1.0:\n",
    "                    pad_h = (h - new_h) // 2\n",
    "                    pad_w = (w - new_w) // 2\n",
    "                    aug_img = cv2.copyMakeBorder(aug_img, pad_h, h - new_h - pad_h,\n",
    "                                                 pad_w, w - new_w - pad_w,\n",
    "                                                 cv2.BORDER_CONSTANT, value=0)\n",
    "                    if mask is not None:\n",
    "                        aug_mask = cv2.copyMakeBorder(aug_mask, pad_h, h - new_h - pad_h,\n",
    "                                                     pad_w, w - new_w - pad_w,\n",
    "                                                     cv2.BORDER_CONSTANT, value=0)\n",
    "                else:\n",
    "                    start_h = (new_h - h) // 2\n",
    "                    start_w = (new_w - w) // 2\n",
    "                    aug_img = aug_img[start_h:start_h + h, start_w:start_w + w]\n",
    "                    if mask is not None:\n",
    "                        aug_mask = aug_mask[start_h:start_h + h, start_w:start_w + w]\n",
    "\n",
    "            elif aug_type == 'noise':\n",
    "                noise = np.random.normal(0, np.random.uniform(3, 8), img_2d.shape)\n",
    "                aug_img = np.clip(img_2d.astype(np.float32) + noise, 0, 255).astype(np.uint8)\n",
    "                aug_mask = mask_2d\n",
    "\n",
    "            elif aug_type == 'brightness':\n",
    "                factor = np.random.uniform(0.9, 1.1)\n",
    "                aug_img = np.clip(img_2d.astype(np.float32) * factor, 0, 255).astype(np.uint8)\n",
    "                aug_mask = mask_2d\n",
    "\n",
    "            # Append\n",
    "            X_augmented.append(aug_img)\n",
    "            y_augmented.append(label)\n",
    "            if mask is not None:\n",
    "                # Binarize to avoid gray artifacts\n",
    "                aug_mask = (aug_mask > 127).astype(np.uint8) * 255\n",
    "                mask_augmented.append(aug_mask)\n",
    "\n",
    "    if masks is not None:\n",
    "        return np.array(X_augmented), np.array(y_augmented), np.array(mask_augmented)\n",
    "    else:\n",
    "        return np.array(X_augmented), np.array(y_augmented)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fdc6383-c073-4ea5-a9fa-20a930f4eafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|█████████████████████████████████████████████████████████████| 235/235 [00:12<00:00, 18.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ORIGINAL DATASET (BEFORE AUGMENTATION)\n",
      "============================================================\n",
      "\n",
      "Training Set Class Distribution:\n",
      "----------------------------------------\n",
      "Normal (Class 0): 124 samples (48.4%)\n",
      "Benign (Class 1): 104 samples (40.6%)\n",
      "Malignant (Class 2): 28 samples (10.9%)\n",
      "Total samples: 256\n",
      "----------------------------------------\n",
      "\n",
      "Validation Set Class Distribution:\n",
      "----------------------------------------\n",
      "Normal (Class 0): 31 samples (48.4%)\n",
      "Benign (Class 1): 26 samples (40.6%)\n",
      "Malignant (Class 2): 7 samples (10.9%)\n",
      "Total samples: 64\n",
      "----------------------------------------\n",
      "\n",
      "Complete Dataset Class Distribution:\n",
      "----------------------------------------\n",
      "Normal (Class 0): 155 samples (48.4%)\n",
      "Benign (Class 1): 130 samples (40.6%)\n",
      "Malignant (Class 2): 35 samples (10.9%)\n",
      "Total samples: 320\n",
      "----------------------------------------\n",
      "\n",
      "============================================================\n",
      "APPLYING DATA AUGMENTATION...\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "AUGMENTED DATASET (AFTER AUGMENTATION)\n",
      "============================================================\n",
      "\n",
      "Augmented Training Set Class Distribution:\n",
      "----------------------------------------\n",
      "Normal (Class 0): 620 samples (66.0%)\n",
      "Benign (Class 1): 208 samples (22.1%)\n",
      "Malignant (Class 2): 112 samples (11.9%)\n",
      "Total samples: 940\n",
      "----------------------------------------\n",
      "\n",
      "Validation Set (unchanged) Class Distribution:\n",
      "----------------------------------------\n",
      "Normal (Class 0): 31 samples (48.4%)\n",
      "Benign (Class 1): 26 samples (40.6%)\n",
      "Malignant (Class 2): 7 samples (10.9%)\n",
      "Total samples: 64\n",
      "----------------------------------------\n",
      "\n",
      "============================================================\n",
      "AUGMENTATION SUMMARY\n",
      "============================================================\n",
      "Original training samples: 256\n",
      "Augmented training samples: 940\n",
      "Augmentation factor: 3.7x\n",
      "\n",
      "Per-class augmentation effect:\n",
      "----------------------------------------\n",
      "Normal: 124 → 620 (5.0x)\n",
      "Benign: 104 → 208 (2.0x)\n",
      "Malignant: 28 → 112 (4.0x)\n",
      "\n",
      "Dataset shapes:\n",
      "Original training set: (256, 1024, 1024), (256,), masks: (256, 1024, 1024)\n",
      "Augmented training set: (940, 1024, 1024), (940,), masks: (940, 1024, 1024)\n",
      "Validation set: (64, 1024, 1024), (64,), masks: (64, 1024, 1024)\n",
      "\n",
      "============================================================\n",
      "ADDITIONAL STATISTICS\n",
      "============================================================\n",
      "Original training set balance ratio: 0.226\n",
      "Augmented training set balance ratio: 0.181\n",
      "Balance improvement: 0.80x better\n",
      "\n",
      "Memory usage:\n",
      "Original training images: 256.0 MB\n",
      "Augmented training images: 940.0 MB\n",
      "Training masks: 940.0 MB\n",
      "Total training data: 1880.0 MB\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "image_dir = \"C:/Users/DragosTrandafiri/BreastCancer_CNN/data/raw/mini_mias/MIAS\" \n",
    "metadata_path = \"C:/Users/DragosTrandafiri/BreastCancer_CNN/data/raw/mini_mias/mias_info.csv\"  \n",
    "output_dir = \"C:/Users/DragosTrandafiri/BreastCancer_CNN/data/processed/mini_mias\"\n",
    "\n",
    "# Create preprocessor\n",
    "preprocessor = MammogramPreprocessor(image_dir, metadata_path, output_dir)\n",
    "\n",
    "\n",
    "# Create dataset\n",
    "X_train, X_val, y_train, y_val, masks_train, masks_val = preprocessor.create_dataset()\n",
    "\n",
    "# Function to print class distribution\n",
    "def print_class_distribution(y, dataset_name):\n",
    "    \"\"\"Print the distribution of classes in the dataset\"\"\"\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    class_names = {0: 'Normal', 1: 'Benign', 2: 'Malignant'}\n",
    "    \n",
    "    print(f\"\\n{dataset_name} Class Distribution:\")\n",
    "    print(\"-\" * 40)\n",
    "    total = len(y)\n",
    "    for class_id, count in zip(unique, counts):\n",
    "        class_name = class_names.get(class_id, f'Class_{class_id}')\n",
    "        percentage = (count / total) * 100\n",
    "        print(f\"{class_name} (Class {class_id}): {count} samples ({percentage:.1f}%)\")\n",
    "    print(f\"Total samples: {total}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# Print original distributions\n",
    "print(\"=\"*60)\n",
    "print(\"ORIGINAL DATASET (BEFORE AUGMENTATION)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print_class_distribution(y_train, \"Training Set\")\n",
    "print_class_distribution(y_val, \"Validation Set\")\n",
    "\n",
    "# Combine train and val to show overall distribution\n",
    "y_total = np.concatenate([y_train, y_val])\n",
    "print_class_distribution(y_total, \"Complete Dataset\")\n",
    "\n",
    "# Apply data augmentation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"APPLYING DATA AUGMENTATION...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "X_train_aug, y_train_aug, masks_train_aug = data_augmentation(X_train, y_train, masks=masks_train)\n",
    "\n",
    "# Print augmented distributions\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"AUGMENTED DATASET (AFTER AUGMENTATION)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print_class_distribution(y_train_aug, \"Augmented Training Set\")\n",
    "print_class_distribution(y_val, \"Validation Set (unchanged)\")\n",
    "\n",
    "# Show augmentation effect\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"AUGMENTATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"Original training samples: {len(y_train)}\")\n",
    "print(f\"Augmented training samples: {len(y_train_aug)}\")\n",
    "print(f\"Augmentation factor: {len(y_train_aug) / len(y_train):.1f}x\")\n",
    "\n",
    "# Show per-class augmentation effect\n",
    "print(\"\\nPer-class augmentation effect:\")\n",
    "print(\"-\" * 40)\n",
    "for class_id in [0, 1, 2]:\n",
    "    original_count = np.sum(y_train == class_id)\n",
    "    augmented_count = np.sum(y_train_aug == class_id)\n",
    "    if original_count > 0:\n",
    "        factor = augmented_count / original_count\n",
    "        class_names = {0: 'Normal', 1: 'Benign', 2: 'Malignant'}\n",
    "        class_name = class_names.get(class_id, f'Class_{class_id}')\n",
    "        print(f\"{class_name}: {original_count} → {augmented_count} ({factor:.1f}x)\")\n",
    "\n",
    "print(f\"\\nDataset shapes:\")\n",
    "print(f\"Original training set: {X_train.shape}, {y_train.shape}, masks: {masks_train.shape}\")\n",
    "print(f\"Augmented training set: {X_train_aug.shape}, {y_train_aug.shape}, masks: {masks_train_aug.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}, {y_val.shape}, masks: {masks_val.shape}\")\n",
    "\n",
    "# Additional statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ADDITIONAL STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate class balance metrics\n",
    "def calculate_balance_metrics(y):\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    max_count = np.max(counts)\n",
    "    min_count = np.min(counts)\n",
    "    balance_ratio = min_count / max_count\n",
    "    return balance_ratio\n",
    "\n",
    "original_balance = calculate_balance_metrics(y_train)\n",
    "augmented_balance = calculate_balance_metrics(y_train_aug)\n",
    "\n",
    "print(f\"Original training set balance ratio: {original_balance:.3f}\")\n",
    "print(f\"Augmented training set balance ratio: {augmented_balance:.3f}\")\n",
    "print(f\"Balance improvement: {(augmented_balance/original_balance):.2f}x better\")\n",
    "\n",
    "# Show memory usage\n",
    "def get_memory_usage_mb(array):\n",
    "    return array.nbytes / (1024 * 1024)\n",
    "\n",
    "print(f\"\\nMemory usage:\")\n",
    "print(f\"Original training images: {get_memory_usage_mb(X_train):.1f} MB\")\n",
    "print(f\"Augmented training images: {get_memory_usage_mb(X_train_aug):.1f} MB\")\n",
    "print(f\"Training masks: {get_memory_usage_mb(masks_train_aug):.1f} MB\")\n",
    "print(f\"Total training data: {get_memory_usage_mb(X_train_aug) + get_memory_usage_mb(masks_train_aug):.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0cd6783-d279-4165-9098-3139d1a32bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (from opencv-python) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (2.1.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (3.10.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (1.6.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (4.67.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (1.15.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dragostrandafiri\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install numpy pandas matplotlib scikit-learn tqdm scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be603c2-b0f2-4fc1-856b-b2bb0fe169ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
