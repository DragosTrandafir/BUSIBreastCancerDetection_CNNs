{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80bd965e-8dda-4f47-a282-f711860d7249",
   "metadata": {},
   "source": [
    "# Preprocessing BUSI dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe8cd10-8338-4d74-86d1-b192db9d09ee",
   "metadata": {},
   "source": [
    "# Important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa2762d0-7297-495c-b3a8-29becf798d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902c2357-a76a-4c01-b93b-ca4045ea610f",
   "metadata": {},
   "source": [
    "# Preprocessing class with all needed functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "977f7569-4d9f-4a7d-b23a-458d47081a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BUSIPreprocessor:\n",
    "    def __init__(self, data_dir, output_dir, img_size=(224, 224)):\n",
    "        \"\"\"\n",
    "        Initialize the BUSI dataset preprocessor.\n",
    "        \n",
    "        Args:\n",
    "            data_dir: Directory containing the BUSI dataset with benign, malignant, normal folders\n",
    "            output_dir: Directory to save processed images\n",
    "            img_size: Target size for the processed images\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.output_dir = output_dir\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        # Create output directories if they don't exist\n",
    "        for class_name in ['benign', 'malignant', 'normal']:\n",
    "            os.makedirs(os.path.join(output_dir, \"processed_images\", class_name), exist_ok=True)\n",
    "        \n",
    "        # Define class mapping\n",
    "        self.class_mapping = {\n",
    "            'normal': 0,\n",
    "            'benign': 1,\n",
    "            'malignant': 2\n",
    "        }\n",
    "        \n",
    "        \n",
    "    # loading an image and grayscaling it if necessary\n",
    "    def load_image(self, image_path):\n",
    "        \"\"\"Load an image and convert to grayscale if needed.\"\"\"\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Could not load image: {image_path}\")\n",
    "        \n",
    "        # Convert to grayscale if it's a color image\n",
    "        if len(img.shape) == 3:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        return img\n",
    "\n",
    "    \n",
    "\n",
    "    # Annotations removal (letters, texts, drawings) & top left corner annotation removal\n",
    "    def add_corner_triangle_mask(self, img):\n",
    "        \"\"\"\n",
    "        Adds a black triangle mask to the left corner of the image\n",
    "        \"\"\"\n",
    "        height, width = img.shape[:2]\n",
    "        \n",
    "        # Create a copy of the input image\n",
    "        result = img.copy()\n",
    "        \n",
    "        # Define triangle vertices (adjust these coordinates as needed)\n",
    "        # Format: top-left corner, bottom-left corner, and a point to the right\n",
    "        triangle_pts = np.array([[0, 0], [0, height//16], [width//16, 0]], np.int32)\n",
    "        \n",
    "        # Fill the triangle with black (0)\n",
    "        cv2.fillPoly(result, [triangle_pts], 0)\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def remove_annotations(self, img):\n",
    "        # Threshold for bright pixels\n",
    "        _, mask = cv2.threshold(img, 220, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "        # Morphological operations to remove thin text/crosses\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "        mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "    \n",
    "        # Inpaint\n",
    "        inpainted = cv2.inpaint(img, mask, inpaintRadius=1, flags=cv2.INPAINT_TELEA)\n",
    "    \n",
    "        return inpainted\n",
    "\n",
    "\n",
    "        \n",
    "    # Filters applied to the BUSI images\n",
    "    def enhance_contrast(self, img):\n",
    "        \"\"\"\n",
    "        Enhance image contrast using adaptive CLAHE,\n",
    "        tuned for ultrasound images.\n",
    "        \"\"\"\n",
    "        if img.dtype != np.uint8:\n",
    "            img = (img * 255).astype(np.uint8)\n",
    "    \n",
    "        # Adaptive CLAHE parameters for ultrasound images\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        enhanced = clahe.apply(img)\n",
    "        return enhanced\n",
    "    \n",
    "    def normalize_image(self, img):\n",
    "        \"\"\"\n",
    "        Normalize image to [0, 1] range.\n",
    "        \"\"\"\n",
    "        img = img.astype(np.float32)\n",
    "        \n",
    "        # Normalize to 0-1 range\n",
    "        img_min = np.min(img)\n",
    "        img_max = np.max(img)\n",
    "        \n",
    "        if img_max > img_min:\n",
    "            img = (img - img_min) / (img_max - img_min)\n",
    "        \n",
    "        return img\n",
    "    \n",
    "\n",
    "\n",
    "    # Resizing to a standard form, to help avoid CNN bias\n",
    "    def resize_with_padding(self, img, target_size):\n",
    "        h, w = img.shape[:2]\n",
    "        target_h, target_w = target_size\n",
    "    \n",
    "        # Compute scale and new size\n",
    "        scale = min(target_w / w, target_h / h)\n",
    "        new_w, new_h = int(w * scale), int(h * scale)\n",
    "    \n",
    "        # Resize while preserving aspect ratio\n",
    "        resized_img = cv2.resize(img, (new_w, new_h))\n",
    "    \n",
    "        # Create a black canvas\n",
    "        padded_img = np.zeros((target_h, target_w), dtype=resized_img.dtype)\n",
    "    \n",
    "        # Compute padding offsets\n",
    "        x_offset = (target_w - new_w) // 2\n",
    "        y_offset = (target_h - new_h) // 2\n",
    "    \n",
    "        # Place the resized image on the canvas\n",
    "        padded_img[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = resized_img\n",
    "    \n",
    "        return padded_img\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    # All steps in processing an image (the order is important for efficiency and reliability)\n",
    "    def process_image(self, image_path, class_name, save=True):\n",
    "        \"\"\"Process a single ultrasound image.\"\"\"\n",
    "    \n",
    "        # Extract the image filename\n",
    "        filename = os.path.basename(image_path)\n",
    "        name_without_ext = os.path.splitext(filename)[0]\n",
    "        \n",
    "        # Load the image\n",
    "        original_img = self.load_image(image_path)\n",
    "\n",
    "        #  Top left corner annotation removal & annotations removal (letters, texts, drawings)\n",
    "        img_left_corner_removed = self.add_corner_triangle_mask(original_img)\n",
    "        img_reduced = self.remove_annotations(img_left_corner_removed)\n",
    "        \n",
    "        # Filters\n",
    "        img_enhanced = self.enhance_contrast(img_reduced) # Enhance contrast\n",
    "        img_normalized = self.normalize_image(img_enhanced) # Normalize the image\n",
    "        \n",
    "        # Resize the image to the target size (224,224) -> useful for the CNN \n",
    "        img_resized = self.resize_with_padding(img_enhanced, self.img_size)\n",
    "        \n",
    "        # Save the processed image\n",
    "        if save:\n",
    "            output_path = os.path.join(self.output_dir, \"processed_images\", class_name, \n",
    "                                     f\"{name_without_ext}_processed.png\")\n",
    "            cv2.imwrite(output_path, img_resized)\n",
    "        \n",
    "        return {\n",
    "            'filename': filename,\n",
    "            'class': class_name,\n",
    "            'processed_image': img_resized,\n",
    "            'normalized_image': self.resize_with_padding((img_normalized * 255).astype(np.uint8), self.img_size)\n",
    "        }\n",
    "\n",
    "    # For mask, only resing is needed    \n",
    "    def process_mask_image(self, mask_path, class_name, save=True):\n",
    "        \"\"\"Process a mask image without any modifications.\"\"\"\n",
    "        # Extract the mask filename\n",
    "        filename = os.path.basename(mask_path)\n",
    "        name_without_ext = os.path.splitext(filename)[0]\n",
    "        \n",
    "        # Load the mask image\n",
    "        mask_img = self.load_image(mask_path)\n",
    "        \n",
    "        # Only resize the mask to match the target size, no other processing\n",
    "        mask_resized = self.resize_with_padding(mask_img, self.img_size)\n",
    "        \n",
    "        # Save the mask image\n",
    "        if save:\n",
    "            output_path = os.path.join(self.output_dir, \"processed_images\", class_name, filename)\n",
    "            cv2.imwrite(output_path, mask_resized)\n",
    "        \n",
    "        return {\n",
    "            'filename': filename,\n",
    "            'class': class_name,\n",
    "            'mask_image': mask_resized\n",
    "        }\n",
    "\n",
    "        \n",
    "    \n",
    "    def get_image_files(self, class_folder):\n",
    "        \"\"\"\n",
    "        Get all image files from a class folder, excluding mask files.\n",
    "        Returns both regular images and their corresponding mask files (if they exist).\n",
    "        \"\"\"\n",
    "        image_extensions = ['*.png', '*.jpg', '*.jpeg', '*.bmp', '*.tiff']\n",
    "        image_files = []\n",
    "        mask_files = []\n",
    "        \n",
    "        for ext in image_extensions:\n",
    "            files = glob.glob(os.path.join(class_folder, ext))\n",
    "            \n",
    "            # Separate regular images and mask images\n",
    "            for f in files:\n",
    "                if '_mask' in os.path.basename(f).lower():\n",
    "                    mask_files.append(f)\n",
    "                else:\n",
    "                    image_files.append(f)\n",
    "        \n",
    "        return image_files, mask_files\n",
    "\n",
    "\n",
    "    def process_all_images(self):\n",
    "        \"\"\"Process all images and their masks in the dataset.\"\"\"\n",
    "        image_results = []\n",
    "        mask_results = []\n",
    "        \n",
    "        for class_name in ['malignant', 'normal', 'benign']:\n",
    "            class_folder = os.path.join(self.data_dir, class_name)\n",
    "            \n",
    "            if not os.path.exists(class_folder):\n",
    "                print(f\"Warning: Folder {class_folder} does not exist. Skipping...\")\n",
    "                continue\n",
    "            \n",
    "            # Get both regular images and mask images\n",
    "            image_files, mask_files = self.get_image_files(class_folder)\n",
    "            print(f\"Found {len(image_files)} images and {len(mask_files)} masks in {class_name} folder\")\n",
    "            \n",
    "            # Process regular images\n",
    "            for image_path in tqdm(image_files, desc=f\"Processing {class_name} images\"):\n",
    "                try:\n",
    "                    result = self.process_image(image_path, class_name)\n",
    "                    image_results.append(result)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {image_path}: {e}\")\n",
    "            \n",
    "            # Process mask images (without modifications)\n",
    "            for mask_path in tqdm(mask_files, desc=f\"Processing {class_name} masks\"):\n",
    "                try:\n",
    "                    result = self.process_mask_image(mask_path, class_name)\n",
    "                    mask_results.append(result)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing mask {mask_path}: {e}\")\n",
    "        \n",
    "        return image_results, mask_results\n",
    "\n",
    "    \n",
    "    def create_dataset(self, use_normalized=True, combine_masks=True):\n",
    "        \"\"\"Create a dataset for training a CNN.\"\"\"\n",
    "        image_data, mask_data = self.process_all_images()\n",
    "    \n",
    "        # Create dictionaries for easy matching - supports multiple masks per image\n",
    "        mask_dict = {}\n",
    "        for mask in mask_data:\n",
    "            # Extract base filename without _mask suffix and any additional suffixes like _1\n",
    "            mask_filename = mask['filename']\n",
    "            # Remove file extension first\n",
    "            base_name = os.path.splitext(mask_filename)[0]\n",
    "            # Remove _mask and any additional suffixes like _1, _2, etc.\n",
    "            if '_mask' in base_name:\n",
    "                base_name = base_name.split('_mask')[0]\n",
    "            \n",
    "            # Store multiple masks per image in a list\n",
    "            if base_name not in mask_dict:\n",
    "                mask_dict[base_name] = []\n",
    "            mask_dict[base_name].append(mask['mask_image'])\n",
    "        \n",
    "        # Create X (images), y (labels), and masks\n",
    "        X = []\n",
    "        y = []\n",
    "        masks = []\n",
    "        filenames = []\n",
    "        \n",
    "        for data in image_data:\n",
    "            # Extract base name from the current image\n",
    "            img_filename = data['filename']\n",
    "            img_base_name = os.path.splitext(img_filename)[0]\n",
    "            \n",
    "            if use_normalized:\n",
    "                X.append(data['normalized_image'])\n",
    "            else:\n",
    "                X.append(data['processed_image'])\n",
    "            \n",
    "            y.append(self.class_mapping[data['class']])\n",
    "            \n",
    "            # Get corresponding masks\n",
    "            if img_base_name in mask_dict:\n",
    "                img_masks = mask_dict[img_base_name]\n",
    "                \n",
    "                if len(img_masks) == 1:\n",
    "                    masks.append(img_masks[0])\n",
    "                elif combine_masks:\n",
    "                    # Combine multiple masks by taking the maximum value at each pixel\n",
    "                    combined_mask = np.maximum.reduce(img_masks)\n",
    "                    masks.append(combined_mask)\n",
    "                    print(f\"Combined {len(img_masks)} masks for {img_filename}\")\n",
    "                else:\n",
    "                    # Just use the first mask if not combining\n",
    "                    masks.append(img_masks[0])\n",
    "                    print(f\"Using first mask out of {len(img_masks)} for {img_filename}\")\n",
    "            else:\n",
    "                # If no mask found, create a blank mask\n",
    "                blank_mask = np.zeros(self.img_size, dtype=np.uint8)\n",
    "                masks.append(blank_mask)\n",
    "                print(f\"Warning: No mask found for {img_filename}, using blank mask\")\n",
    "            \n",
    "            filenames.append(data['filename'])\n",
    "        \n",
    "        # Convert to numpy arrays\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        masks = np.array(masks)\n",
    "    \n",
    "        # Add channel dimension if needed (for CNN)\n",
    "        if len(X.shape) == 3:\n",
    "            X = np.expand_dims(X, axis=-1)\n",
    "        if len(masks.shape) == 3:\n",
    "            masks = np.expand_dims(masks, axis=-1)\n",
    "        \n",
    "        print(f\"Dataset shape: {X.shape}\")\n",
    "        print(f\"Masks shape: {masks.shape}\")\n",
    "        print(f\"Labels shape: {y.shape}\")\n",
    "        print(f\"Class distribution: Normal: {np.sum(y == 0)}, Benign: {np.sum(y == 1)}, Malignant: {np.sum(y == 2)}\")\n",
    "        \n",
    "        # Split into training and validation sets\n",
    "        X_train, X_val, y_train, y_val, masks_train, masks_val = train_test_split(\n",
    "            X, y, masks, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        return X_train, X_val, y_train, y_val, masks_train, masks_val, filenames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448328ba-0cd7-466c-965a-e25cec824bef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
