{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80bd965e-8dda-4f47-a282-f711860d7249",
   "metadata": {},
   "source": [
    "# Preprocessing BUSI dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe8cd10-8338-4d74-86d1-b192db9d09ee",
   "metadata": {},
   "source": [
    "# Important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa2762d0-7297-495c-b3a8-29becf798d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902c2357-a76a-4c01-b93b-ca4045ea610f",
   "metadata": {},
   "source": [
    "# Preprocessing class with all needed functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805172dc-6069-4e95-97dc-a7d38ece00a9",
   "metadata": {},
   "source": [
    "## Core Methods\n",
    "1. load_image(image_path)\n",
    "\n",
    "Loads an image using OpenCV. Converts to grayscale if needed.\n",
    "\n",
    "2. add_corner_triangle_mask(img)\n",
    "\n",
    "Adds a black triangular mask in the top-left corner to remove ultrasound annotations.\n",
    "\n",
    "3. remove_annotations(img)\n",
    "\n",
    "Removes bright annotations (e.g., text/drawings) using inpainting.\n",
    "\n",
    "4. enhance_contrast(img)\n",
    "\n",
    "Applies CLAHE (adaptive histogram equalization) to improve image contrast.\n",
    "\n",
    "5. resize_with_padding(img, target_size)\n",
    "\n",
    "Resizes an image while preserving aspect ratio. Pads with black pixels to match target_size.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490f1c9e-6253-49d5-81b4-34bcf4680d99",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3b7bbb-567a-4240-b037-1d69fede42d9",
   "metadata": {},
   "source": [
    "## Image Processing Pipeline\n",
    "6. process_image(image_path, class_name, save=True)\n",
    "\n",
    "Processes a single image using the full pipeline:\n",
    "\n",
    "Loads the image\n",
    "\n",
    "Removes corner mask and annotations\n",
    "\n",
    "Enhances contrast\n",
    "\n",
    "Resizes to uniform dimensions\n",
    "\n",
    "Optionally saves the processed image\n",
    "\n",
    "7. process_mask_image(mask_path, class_name, save=True)\n",
    "\n",
    "Only resizes the corresponding segmentation mask. No filtering applied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8975a2-e8f5-46d0-9db6-c7e813a332dc",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7ca21f-4f3c-4dfc-b940-6ffabd5d0537",
   "metadata": {},
   "source": [
    "## Dataset Utilities\n",
    "8. get_image_files(class_folder)\n",
    "\n",
    "Retrieves all .png images from a class folder and separates image files from mask files.\n",
    "\n",
    "9. process_all_images()\n",
    "\n",
    "Applies the processing pipeline to all images and masks in the BUSI dataset folders.\n",
    "\n",
    "10. create_dataset(combine_masks=True)\n",
    "\n",
    "Creates the final dataset for CNN training:\n",
    "\n",
    "X: Processed images\n",
    "\n",
    "y: Corresponding labels (normal=0, benign=1, malignant=2)\n",
    "\n",
    "masks: Optional segmentation masks\n",
    "\n",
    "Supports combining multiple masks per image using np.maximum.reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75c475a-c149-4627-b654-041a4d41cdbb",
   "metadata": {},
   "source": [
    "Returns:\n",
    "\n",
    "X: np.ndarray of shape (N, 224, 224, 1)\n",
    "\n",
    "y: np.ndarray of shape (N,)\n",
    "\n",
    "masks: np.ndarray of shape (N, 224, 224, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431002a2-ff49-4f53-bde4-a87c2df1bccb",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b500c58f-c25c-4659-9284-5137c58b887a",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- The order of preprocessing operations is carefully chosen for robustness.\n",
    "\n",
    "- Blank masks are automatically generated if none are found.\n",
    "\n",
    "- Prints dataset statistics after creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "977f7569-4d9f-4a7d-b23a-458d47081a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BUSIPreprocessor:\n",
    "    def __init__(self, data_dir, output_dir, img_size=(224, 224)):\n",
    "        \"\"\"\n",
    "        Initialize the BUSI dataset preprocessor.\n",
    "        \n",
    "        Args:\n",
    "            data_dir: Directory containing the BUSI dataset with benign, malignant, normal folders\n",
    "            output_dir: Directory to save processed images\n",
    "            img_size: Target size for the processed images\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.output_dir = output_dir\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        # Create output directories if they don't exist\n",
    "        for class_name in ['benign', 'malignant', 'normal']:\n",
    "            os.makedirs(os.path.join(output_dir, \"processed_images\", class_name), exist_ok=True)\n",
    "        \n",
    "        # Define class mapping\n",
    "        self.class_mapping = {\n",
    "            'normal': 0,\n",
    "            'benign': 1,\n",
    "            'malignant': 2\n",
    "        }\n",
    "        \n",
    "        \n",
    "    # loading an image and grayscaling it if necessary\n",
    "    def load_image(self, image_path):\n",
    "        \"\"\"Load an image and convert to grayscale if needed.\"\"\"\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Could not load image: {image_path}\")\n",
    "        \n",
    "        # Convert to grayscale if it's a color image\n",
    "        if len(img.shape) == 3:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        return img\n",
    "\n",
    "    \n",
    "\n",
    "    # Annotations removal (letters, texts, drawings) & top left corner annotation removal\n",
    "    def add_corner_triangle_mask(self, img):\n",
    "        \"\"\"\n",
    "        Adds a black triangle mask to the left corner of the image\n",
    "        \"\"\"\n",
    "        height, width = img.shape[:2]\n",
    "        \n",
    "        # Create a copy of the input image\n",
    "        result = img.copy()\n",
    "        \n",
    "        # Define triangle vertices (adjust these coordinates as needed)\n",
    "        # Format: top-left corner, bottom-left corner, and a point to the right\n",
    "        triangle_pts = np.array([[0, 0], [0, height//16], [width//16, 0]], np.int32)\n",
    "        \n",
    "        # Fill the triangle with black (0)\n",
    "        cv2.fillPoly(result, [triangle_pts], 0)\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def remove_annotations(self, img):\n",
    "        # Threshold for bright pixels\n",
    "        _, mask = cv2.threshold(img, 220, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "        # Morphological operations to remove thin text/crosses\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "        mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "    \n",
    "        # Inpaint\n",
    "        inpainted = cv2.inpaint(img, mask, inpaintRadius=1, flags=cv2.INPAINT_TELEA)\n",
    "    \n",
    "        return inpainted\n",
    "\n",
    "\n",
    "        \n",
    "    # Filters applied to the BUSI images\n",
    "    def enhance_contrast(self, img):\n",
    "        \"\"\"\n",
    "        Enhance image contrast using adaptive CLAHE,\n",
    "        tuned for ultrasound images.\n",
    "        \"\"\"\n",
    "        if img.dtype != np.uint8:\n",
    "            img = (img * 255).astype(np.uint8)\n",
    "    \n",
    "        # Adaptive CLAHE parameters for ultrasound images\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        enhanced = clahe.apply(img)\n",
    "        return enhanced\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    # Resizing to a standard form, to help avoid CNN bias\n",
    "    def resize_with_padding(self, img, target_size):\n",
    "        h, w = img.shape[:2]\n",
    "        target_h, target_w = target_size\n",
    "    \n",
    "        # Compute scale and new size\n",
    "        scale = min(target_w / w, target_h / h)\n",
    "        new_w, new_h = int(w * scale), int(h * scale)\n",
    "    \n",
    "        # Resize while preserving aspect ratio\n",
    "        resized_img = cv2.resize(img, (new_w, new_h))\n",
    "    \n",
    "        # Create a black canvas\n",
    "        padded_img = np.zeros((target_h, target_w), dtype=resized_img.dtype)\n",
    "    \n",
    "        # Compute padding offsets\n",
    "        x_offset = (target_w - new_w) // 2\n",
    "        y_offset = (target_h - new_h) // 2\n",
    "    \n",
    "        # Place the resized image on the canvas\n",
    "        padded_img[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = resized_img\n",
    "    \n",
    "        return padded_img\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    # All steps in processing an image (the order is important for efficiency and reliability)\n",
    "    def process_image(self, image_path, class_name, save=True):\n",
    "        \"\"\"Process a single ultrasound image.\"\"\"\n",
    "    \n",
    "        # Extract the image filename\n",
    "        filename = os.path.basename(image_path)\n",
    "        name_without_ext = os.path.splitext(filename)[0]\n",
    "        \n",
    "        # Load the image\n",
    "        original_img = self.load_image(image_path)\n",
    "\n",
    "        #  Top left corner annotation removal & annotations removal (letters, texts, drawings)\n",
    "        img_left_corner_removed = self.add_corner_triangle_mask(original_img)\n",
    "        img_reduced = self.remove_annotations(img_left_corner_removed)\n",
    "        \n",
    "        # Filters\n",
    "        img_enhanced = self.enhance_contrast(img_reduced) # Enhance contrast\n",
    "        \n",
    "        # Resize the image to the target size (224,224) -> useful for the CNN \n",
    "        img_resized = self.resize_with_padding(img_enhanced, self.img_size)\n",
    "        \n",
    "        # Save the processed image\n",
    "        if save:\n",
    "            output_path = os.path.join(self.output_dir, \"processed_images\", class_name, \n",
    "                                     f\"{name_without_ext}_processed.png\")\n",
    "            cv2.imwrite(output_path, img_resized)\n",
    "        \n",
    "        return {\n",
    "            'filename': filename,\n",
    "            'class': class_name,\n",
    "            'processed_image': img_resized\n",
    "        }\n",
    "\n",
    "    # For mask, only resing is needed    \n",
    "    def process_mask_image(self, mask_path, class_name, save=True):\n",
    "        \"\"\"Process a mask image without any modifications.\"\"\"\n",
    "        # Extract the mask filename\n",
    "        filename = os.path.basename(mask_path)\n",
    "        name_without_ext = os.path.splitext(filename)[0]\n",
    "        \n",
    "        # Load the mask image\n",
    "        mask_img = self.load_image(mask_path)\n",
    "        \n",
    "        # Only resize the mask to match the target size, no other processing\n",
    "        mask_resized = self.resize_with_padding(mask_img, self.img_size)\n",
    "        \n",
    "        # Save the mask image\n",
    "        if save:\n",
    "            output_path = os.path.join(self.output_dir, \"processed_images\", class_name, filename)\n",
    "            cv2.imwrite(output_path, mask_resized)\n",
    "        \n",
    "        return {\n",
    "            'filename': filename,\n",
    "            'class': class_name,\n",
    "            'mask_image': mask_resized\n",
    "        }\n",
    "\n",
    "        \n",
    "    \n",
    "    def get_image_files(self, class_folder):\n",
    "        \"\"\"\n",
    "        Get all image files from a class folder, excluding mask files.\n",
    "        Returns both regular images and their corresponding mask files (if they exist).\n",
    "        \"\"\"\n",
    "        image_files = []\n",
    "        mask_files = []\n",
    "        \n",
    "        files = glob.glob(os.path.join(class_folder, '*.png'))\n",
    "        \n",
    "        # Separate regular images and mask images\n",
    "        for f in files:\n",
    "            if '_mask' in os.path.basename(f).lower():\n",
    "                mask_files.append(f)\n",
    "            else:\n",
    "                image_files.append(f)\n",
    "        \n",
    "        return image_files, mask_files\n",
    "\n",
    "\n",
    "    def process_all_images(self, label):\n",
    "        \"\"\"Process all images and their masks in the dataset.\"\"\"\n",
    "        image_results = []\n",
    "        mask_results = []\n",
    "\n",
    "        \n",
    "        class_folder = os.path.join(self.data_dir, label)\n",
    "        \n",
    "        if not os.path.exists(class_folder):\n",
    "            print(f\"Warning: Folder {class_folder} does not exist. Skipping...\")\n",
    "        \n",
    "        # Get both regular images and mask images\n",
    "        image_files, mask_files = self.get_image_files(class_folder)\n",
    "        print(f\"Found {len(image_files)} images and {len(mask_files)} masks in {label} folder\")\n",
    "        \n",
    "        # Process regular images\n",
    "        for image_path in tqdm(image_files, desc=f\"Processing {label} images\"):\n",
    "            try:\n",
    "                result = self.process_image(image_path, label)\n",
    "                image_results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {image_path}: {e}\")\n",
    "        \n",
    "        # Process mask images (without modifications)\n",
    "        for mask_path in tqdm(mask_files, desc=f\"Processing {label} masks\"):\n",
    "            try:\n",
    "                result = self.process_mask_image(mask_path, label)\n",
    "                mask_results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing mask {mask_path}: {e}\")\n",
    "        \n",
    "        return image_results, mask_results\n",
    "\n",
    "    \n",
    "    def create_dataset(self, label, combine_masks=True):\n",
    "        \"\"\"Create a dataset for training a CNN.\"\"\"\n",
    "        image_data, mask_data = self.process_all_images(label)\n",
    "    \n",
    "        # Create dictionaries for easy matching - supports multiple masks per image\n",
    "        mask_dict = {}\n",
    "        for mask in mask_data:\n",
    "            # Extract base filename without _mask suffix and any additional suffixes like _1\n",
    "            mask_filename = mask['filename']\n",
    "            # Remove file extension first\n",
    "            base_name = os.path.splitext(mask_filename)[0]\n",
    "            # Remove _mask and any additional suffixes like _1, _2, etc.\n",
    "            if '_mask' in base_name:\n",
    "                base_name = base_name.split('_mask')[0]\n",
    "            \n",
    "            # Store multiple masks per image in a list\n",
    "            if base_name not in mask_dict:\n",
    "                mask_dict[base_name] = []\n",
    "            mask_dict[base_name].append(mask['mask_image'])\n",
    "        \n",
    "        # Create X (images), y (labels), and masks\n",
    "        X = []\n",
    "        y = []\n",
    "        masks = []\n",
    "        filenames = []\n",
    "        \n",
    "        for data in image_data:\n",
    "            # Extract base name from the current image\n",
    "            img_filename = data['filename']\n",
    "            img_base_name = os.path.splitext(img_filename)[0]\n",
    "            \n",
    "\n",
    "            X.append(data['processed_image'])\n",
    "            \n",
    "            y.append(self.class_mapping[data['class']])\n",
    "            \n",
    "            # Get corresponding masks\n",
    "            if img_base_name in mask_dict:\n",
    "                img_masks = mask_dict[img_base_name]\n",
    "                \n",
    "                if len(img_masks) == 1:\n",
    "                    masks.append(img_masks[0])\n",
    "                elif combine_masks:\n",
    "                    # Combine multiple masks by taking the maximum value at each pixel\n",
    "                    combined_mask = np.maximum.reduce(img_masks)\n",
    "                    masks.append(combined_mask)\n",
    "                    print(f\"Combined {len(img_masks)} masks for {img_filename}\")\n",
    "                else:\n",
    "                    # Just use the first mask if not combining\n",
    "                    masks.append(img_masks[0])\n",
    "                    print(f\"Using first mask out of {len(img_masks)} for {img_filename}\")\n",
    "            else:\n",
    "                # If no mask found, create a blank mask\n",
    "                blank_mask = np.zeros(self.img_size, dtype=np.uint8)\n",
    "                masks.append(blank_mask)\n",
    "                print(f\"Warning: No mask found for {img_filename}, using blank mask\")\n",
    "            \n",
    "            filenames.append(data['filename'])\n",
    "        \n",
    "        # Convert to numpy arrays\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        masks = np.array(masks)\n",
    "    \n",
    "        # Add channel dimension if needed (for CNN)\n",
    "        if len(X.shape) == 3:\n",
    "            X = np.expand_dims(X, axis=-1)\n",
    "        if len(masks.shape) == 3:\n",
    "            masks = np.expand_dims(masks, axis=-1)\n",
    "        \n",
    "        print(f\"Dataset shape: {X.shape}\")\n",
    "        print(f\"Masks shape: {masks.shape}\")\n",
    "        print(f\"Labels shape: {y.shape}\")\n",
    "        print(f\"Class distribution: Normal: {np.sum(y == 0)}, Benign: {np.sum(y == 1)}, Malignant: {np.sum(y == 2)}\")\n",
    "        \n",
    "        return X, y, masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448328ba-0cd7-466c-965a-e25cec824bef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
