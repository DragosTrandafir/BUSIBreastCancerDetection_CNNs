{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aadb85c5-5d1e-4d24-80b6-e4353e413c78",
   "metadata": {},
   "source": [
    "# Custom CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df1f0d67-2fda-4ae1-a81b-6cd1eb104f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 210 images and 211 masks in malignant folder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing malignant images: 100%|███████████████████████████████████████████████████| 210/210 [00:02<00:00, 95.91it/s]\n",
      "Processing malignant masks: 100%|███████████████████████████████████████████████████| 211/211 [00:00<00:00, 563.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 133 images and 133 masks in normal folder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing normal images: 100%|██████████████████████████████████████████████████████| 133/133 [00:01<00:00, 87.01it/s]\n",
      "Processing normal masks: 100%|██████████████████████████████████████████████████████| 133/133 [00:00<00:00, 257.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 437 images and 454 masks in benign folder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing benign images: 100%|██████████████████████████████████████████████████████| 437/437 [00:04<00:00, 94.21it/s]\n",
      "Processing benign masks: 100%|██████████████████████████████████████████████████████| 454/454 [00:00<00:00, 628.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined 2 masks for malignant (53).png\n",
      "Combined 2 masks for benign (100).png\n",
      "Combined 2 masks for benign (163).png\n",
      "Combined 2 masks for benign (173).png\n",
      "Combined 2 masks for benign (181).png\n",
      "Combined 3 masks for benign (195).png\n",
      "Combined 2 masks for benign (25).png\n",
      "Combined 2 masks for benign (315).png\n",
      "Combined 2 masks for benign (346).png\n",
      "Combined 2 masks for benign (4).png\n",
      "Combined 2 masks for benign (424).png\n",
      "Combined 2 masks for benign (54).png\n",
      "Combined 2 masks for benign (58).png\n",
      "Combined 2 masks for benign (83).png\n",
      "Combined 2 masks for benign (92).png\n",
      "Combined 2 masks for benign (93).png\n",
      "Combined 2 masks for benign (98).png\n",
      "Dataset shape: (780, 224, 224, 1)\n",
      "Masks shape: (780, 224, 224, 1)\n",
      "Labels shape: (780,)\n",
      "Class distribution: Normal: 133, Benign: 437, Malignant: 210\n",
      "Training set sizes: X_train: (546, 224, 224, 1), y_train: (546,), masks: (780, 224, 224, 1)\n",
      "Augmented training set sizes: X_aug: (1758, 224, 224, 1), y_aug: (1758,), masks: (1758, 224, 224, 1)\n",
      "Validation set sizes: X_val: (117, 224, 224, 1), y_val: (117,), masks: (117, 224, 224, 1)\n",
      "Test set sizes: X_test: (117, 224, 224, 1), y_test: (117,), masks: (117, 224, 224, 1)\n",
      "Augmented Normal: 558 samples\n",
      "Augmented Benign: 612 samples\n",
      "Augmented Malignant: 588 samples\n",
      "Augmented images saved to: C:/Users/DragosTrandafiri/BreastCancer_CNN/data/processed/busi/processed_images_augmented/X\n"
     ]
    }
   ],
   "source": [
    "# Run the previous notebook to load all its classes and functions\n",
    "%run busi_augmentation_2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eb4f114-0c17-496d-8fe3-67a6deddc5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, LeakyReLU, BatchNormalization, Conv2D, MaxPooling2D, Flatten,  Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist, cifar10\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a935f603-5aa8-4969-be7e-85a0352fde43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1758, 224, 224, 1)\n",
      "(1758,)\n",
      "(1758, 224, 224, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_aug.shape)\n",
    "print(y_aug.shape)\n",
    "print(masks_aug.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3dff71-c4f4-4f64-a31b-441c6be23b99",
   "metadata": {},
   "source": [
    "# Apply MINMAX normalization (suitable for CNNs custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e558a08-7d48-4a4e-b7ae-7365b111ccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "X_train_aug = X_aug.astype(\"float32\") / 255.0\n",
    "masks_train_aug = masks_aug.astype(\"float32\") / 255.0\n",
    "y_train_aug = y_aug\n",
    "\n",
    "# Test\n",
    "X_test = X_test.astype(\"float32\") / 255.0\n",
    "masks_test = masks_test.astype(\"float32\") / 255.0\n",
    "y_test = y_test\n",
    "\n",
    "# Validation\n",
    "X_val = X_val.astype(\"float32\") / 255.0\n",
    "masks_val = masks_val.astype(\"float32\") / 255.0\n",
    "y_val = y_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6718b1b5-17af-4bf6-ba68-afbe2db715a3",
   "metadata": {},
   "source": [
    "# 1. Model from article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bdd82ad-4cc8-463f-bc16-151d5ea182c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    # Input layer (grayscale images 224x224x1)\n",
    "    Input(shape=(224, 224, 1)),\n",
    "\n",
    "    # Convolutional layer: 20 filters, kernel size 5x5\n",
    "    Conv2D(20, (5, 5), padding=\"same\"),\n",
    "    \n",
    "    # Batch Normalization (20 channels)\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    # ReLU activation\n",
    "    Activation(\"relu\"),\n",
    "    \n",
    "    # MaxPooling\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Flatten before fully connected\n",
    "    Flatten(),\n",
    "    \n",
    "    # Fully connected layer (let’s use 128 units)\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    \n",
    "    # Dropout 50%\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    # Output layer with 3 classes\n",
    "    Dense(3, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34089342-0e52-4898-bb3c-bc3b56033908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 662ms/step - accuracy: 0.3490 - loss: 45.4109 - val_accuracy: 0.2735 - val_loss: 1.0989\n",
      "Epoch 2/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 645ms/step - accuracy: 0.3522 - loss: 1.1493 - val_accuracy: 0.5641 - val_loss: 1.0962\n",
      "Epoch 3/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 651ms/step - accuracy: 0.3508 - loss: 1.0980 - val_accuracy: 0.5556 - val_loss: 1.0943\n",
      "Epoch 4/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 648ms/step - accuracy: 0.3435 - loss: 1.0986 - val_accuracy: 0.5556 - val_loss: 1.0932\n",
      "Epoch 5/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 647ms/step - accuracy: 0.3555 - loss: 1.0973 - val_accuracy: 0.5556 - val_loss: 1.0898\n",
      "Epoch 6/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 644ms/step - accuracy: 0.3487 - loss: 1.0981 - val_accuracy: 0.5556 - val_loss: 1.0892\n",
      "Epoch 7/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 646ms/step - accuracy: 0.3493 - loss: 1.0978 - val_accuracy: 0.5556 - val_loss: 1.0876\n",
      "Epoch 8/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 643ms/step - accuracy: 0.3609 - loss: 1.0974 - val_accuracy: 0.5556 - val_loss: 1.0866\n",
      "Epoch 9/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 645ms/step - accuracy: 0.3349 - loss: 1.0988 - val_accuracy: 0.5556 - val_loss: 1.0865\n",
      "Epoch 10/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 646ms/step - accuracy: 0.3300 - loss: 1.0956 - val_accuracy: 0.5556 - val_loss: 1.0854\n",
      "Epoch 11/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 643ms/step - accuracy: 0.3428 - loss: 1.0985 - val_accuracy: 0.5556 - val_loss: 1.0844\n",
      "Epoch 12/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 648ms/step - accuracy: 0.3459 - loss: 1.0981 - val_accuracy: 0.5556 - val_loss: 1.0835\n",
      "Epoch 13/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 643ms/step - accuracy: 0.3606 - loss: 1.0967 - val_accuracy: 0.5556 - val_loss: 1.0826\n",
      "Epoch 14/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 645ms/step - accuracy: 0.3570 - loss: 1.0962 - val_accuracy: 0.5556 - val_loss: 1.0830\n",
      "Epoch 15/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 646ms/step - accuracy: 0.3579 - loss: 1.0960 - val_accuracy: 0.5556 - val_loss: 1.0825\n",
      "Restoring model weights from the end of the best epoch: 15.\n"
     ]
    }
   ],
   "source": [
    "# Compile\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    X_train_aug, y_train_aug,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=15,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# Save\n",
    "label = (\n",
    "    f\"custom_CNN_from_Convolutionalneuralnetwork-basedmodelsfordiagnosisofbreast\"\n",
    ")\n",
    "histories.append((label, history))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fb2465-e414-4ecd-b6e3-6bcd62c2ffe2",
   "metadata": {},
   "source": [
    "### Apply early stopping to save time & avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2bfb8ce8-029b-4678-9c93-d5ff951fef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping\n",
    "early_stop = EarlyStopping(patience=5, restore_best_weights=True,monitor='val_loss', verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c324caf8-4fd9-4fc2-b1ff-45071c2bae4c",
   "metadata": {},
   "source": [
    "# 2. Custom CNNs (initial trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab72ade7-4140-436d-afe6-e5b12b42c173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with: activation=relu, dense_layer=32\n",
      "Epoch 1/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 535ms/step - accuracy: 0.3700 - loss: 1.2998 - val_accuracy: 0.5812 - val_loss: 0.9757\n",
      "Epoch 2/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 523ms/step - accuracy: 0.5673 - loss: 0.9334 - val_accuracy: 0.5726 - val_loss: 0.8272\n",
      "Epoch 3/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 522ms/step - accuracy: 0.7537 - loss: 0.6324 - val_accuracy: 0.6496 - val_loss: 0.7889\n",
      "Epoch 4/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 524ms/step - accuracy: 0.8248 - loss: 0.4505 - val_accuracy: 0.5983 - val_loss: 0.9415\n",
      "Epoch 5/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 525ms/step - accuracy: 0.9171 - loss: 0.2377 - val_accuracy: 0.6410 - val_loss: 1.1813\n",
      "Epoch 6/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 525ms/step - accuracy: 0.9516 - loss: 0.1418 - val_accuracy: 0.6667 - val_loss: 1.2107\n",
      "Epoch 7/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 527ms/step - accuracy: 0.9546 - loss: 0.1256 - val_accuracy: 0.6325 - val_loss: 1.5552\n",
      "Epoch 8/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 534ms/step - accuracy: 0.9732 - loss: 0.0851 - val_accuracy: 0.6239 - val_loss: 1.4327\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Training model with: activation=leakyrelu, dense_layer=32\n",
      "Epoch 1/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 579ms/step - accuracy: 0.3531 - loss: 1.4614 - val_accuracy: 0.5470 - val_loss: 0.9782\n",
      "Epoch 2/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 579ms/step - accuracy: 0.5347 - loss: 0.9348 - val_accuracy: 0.6325 - val_loss: 0.8124\n",
      "Epoch 3/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 574ms/step - accuracy: 0.7120 - loss: 0.6754 - val_accuracy: 0.6923 - val_loss: 0.7111\n",
      "Epoch 4/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 583ms/step - accuracy: 0.8638 - loss: 0.3726 - val_accuracy: 0.7436 - val_loss: 0.7834\n",
      "Epoch 5/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 594ms/step - accuracy: 0.9300 - loss: 0.1989 - val_accuracy: 0.7265 - val_loss: 1.0464\n",
      "Epoch 6/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 607ms/step - accuracy: 0.9587 - loss: 0.1150 - val_accuracy: 0.7094 - val_loss: 0.8067\n",
      "Epoch 7/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 599ms/step - accuracy: 0.9813 - loss: 0.0704 - val_accuracy: 0.7179 - val_loss: 1.1487\n",
      "Epoch 8/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 605ms/step - accuracy: 0.9826 - loss: 0.0489 - val_accuracy: 0.7436 - val_loss: 1.1476\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Training model with: activation=relu, dense_layer=64\n",
      "Epoch 1/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2s/step - accuracy: 0.3681 - loss: 1.2456 - val_accuracy: 0.6239 - val_loss: 0.9371\n",
      "Epoch 2/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 2s/step - accuracy: 0.5176 - loss: 0.9670 - val_accuracy: 0.5897 - val_loss: 0.8355\n",
      "Epoch 3/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2s/step - accuracy: 0.7158 - loss: 0.7031 - val_accuracy: 0.6325 - val_loss: 0.7753\n",
      "Epoch 4/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2s/step - accuracy: 0.8066 - loss: 0.4889 - val_accuracy: 0.7094 - val_loss: 0.8546\n",
      "Epoch 5/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2s/step - accuracy: 0.9193 - loss: 0.2404 - val_accuracy: 0.6752 - val_loss: 0.9895\n",
      "Epoch 6/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 2s/step - accuracy: 0.9549 - loss: 0.1346 - val_accuracy: 0.6752 - val_loss: 1.0973\n",
      "Epoch 7/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 2s/step - accuracy: 0.9642 - loss: 0.1017 - val_accuracy: 0.5897 - val_loss: 1.3909\n",
      "Epoch 8/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.9759 - loss: 0.0764 - val_accuracy: 0.7009 - val_loss: 1.2061\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Training model with: activation=leakyrelu, dense_layer=64\n",
      "Epoch 1/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - accuracy: 0.3572 - loss: 1.5244 - val_accuracy: 0.5812 - val_loss: 1.0812\n",
      "Epoch 2/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 2s/step - accuracy: 0.4951 - loss: 1.0253 - val_accuracy: 0.5897 - val_loss: 0.8605\n",
      "Epoch 3/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 2s/step - accuracy: 0.5465 - loss: 0.9090 - val_accuracy: 0.6410 - val_loss: 0.7913\n",
      "Epoch 4/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 2s/step - accuracy: 0.7181 - loss: 0.6834 - val_accuracy: 0.6581 - val_loss: 0.7313\n",
      "Epoch 5/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.8263 - loss: 0.4176 - val_accuracy: 0.7350 - val_loss: 0.6647\n",
      "Epoch 6/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.9298 - loss: 0.1881 - val_accuracy: 0.7436 - val_loss: 0.7912\n",
      "Epoch 7/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.9614 - loss: 0.1060 - val_accuracy: 0.7179 - val_loss: 0.8026\n",
      "Epoch 8/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.9809 - loss: 0.0862 - val_accuracy: 0.7521 - val_loss: 0.9294\n",
      "Epoch 9/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.9866 - loss: 0.0452 - val_accuracy: 0.7265 - val_loss: 1.1233\n",
      "Epoch 10/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 2s/step - accuracy: 0.9868 - loss: 0.0429 - val_accuracy: 0.7265 - val_loss: 0.8742\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Training model with: activation=relu, dense_layer=128\n",
      "Epoch 1/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 6s/step - accuracy: 0.3204 - loss: 2.0159 - val_accuracy: 0.5214 - val_loss: 1.0752\n",
      "Epoch 2/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 6s/step - accuracy: 0.4609 - loss: 1.0526 - val_accuracy: 0.6068 - val_loss: 0.8927\n",
      "Epoch 3/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 5s/step - accuracy: 0.5792 - loss: 0.8896 - val_accuracy: 0.6239 - val_loss: 0.8489\n",
      "Epoch 4/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 5s/step - accuracy: 0.7285 - loss: 0.6546 - val_accuracy: 0.6068 - val_loss: 0.8240\n",
      "Epoch 5/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 5s/step - accuracy: 0.7921 - loss: 0.5257 - val_accuracy: 0.6496 - val_loss: 0.8253\n",
      "Epoch 6/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 5s/step - accuracy: 0.8775 - loss: 0.3153 - val_accuracy: 0.6496 - val_loss: 0.9892\n",
      "Epoch 7/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 5s/step - accuracy: 0.9370 - loss: 0.1807 - val_accuracy: 0.6838 - val_loss: 0.9131\n",
      "Epoch 8/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 5s/step - accuracy: 0.9357 - loss: 0.1641 - val_accuracy: 0.6752 - val_loss: 1.0761\n",
      "Epoch 9/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 6s/step - accuracy: 0.9466 - loss: 0.1211 - val_accuracy: 0.6752 - val_loss: 1.2989\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Training model with: activation=leakyrelu, dense_layer=128\n",
      "Epoch 1/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 6s/step - accuracy: 0.3490 - loss: 1.6764 - val_accuracy: 0.5385 - val_loss: 0.9932\n",
      "Epoch 2/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 6s/step - accuracy: 0.4576 - loss: 1.0467 - val_accuracy: 0.5556 - val_loss: 1.0337\n",
      "Epoch 3/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 6s/step - accuracy: 0.6059 - loss: 0.8815 - val_accuracy: 0.6325 - val_loss: 0.7720\n",
      "Epoch 4/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 6s/step - accuracy: 0.7408 - loss: 0.5942 - val_accuracy: 0.7179 - val_loss: 0.6186\n",
      "Epoch 5/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 6s/step - accuracy: 0.8465 - loss: 0.3992 - val_accuracy: 0.7350 - val_loss: 0.6264\n",
      "Epoch 6/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 6s/step - accuracy: 0.9184 - loss: 0.2283 - val_accuracy: 0.7521 - val_loss: 0.8018\n",
      "Epoch 7/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 6s/step - accuracy: 0.9556 - loss: 0.1475 - val_accuracy: 0.6923 - val_loss: 0.8326\n",
      "Epoch 8/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 6s/step - accuracy: 0.9681 - loss: 0.0896 - val_accuracy: 0.7607 - val_loss: 1.0658\n",
      "Epoch 9/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 6s/step - accuracy: 0.9733 - loss: 0.0723 - val_accuracy: 0.7094 - val_loss: 1.1249\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter options\n",
    "\n",
    "activations = [\n",
    "    (\"relu\", \"relu\"),\n",
    "    (\"leakyrelu\", LeakyReLU(negative_slope=0.01))\n",
    "]\n",
    "dense_layers =[32, 64, 128]\n",
    "\n",
    "\n",
    "histories = []\n",
    "\n",
    "\n",
    "for dense_nr in dense_layers:\n",
    "    for activation_name, activation_fn in activations:\n",
    "            print(\n",
    "                f\"Training model with: \"\n",
    "                f\"activation={activation_name}, \"\n",
    "                f\"dense_layer={dense_nr}\"\n",
    "            )\n",
    "\n",
    "\n",
    "            # Model definition\n",
    "            model = Sequential([\n",
    "                Input(shape=(224, 224, 1)),\n",
    "                Conv2D(dense_nr, kernel_size=(3,3), activation=activation_fn),\n",
    "                MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "                Conv2D(dense_nr*2, kernel_size=(3,3), activation=activation_fn),\n",
    "                MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "                Conv2D(dense_nr*4, kernel_size=(3,3), activation=activation_fn),\n",
    "                MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "                Flatten(),\n",
    "                Dense(128, activation=activation_fn),\n",
    "                Dropout(0.5),\n",
    "                Dense(3, activation='softmax')\n",
    "            ])\n",
    "\n",
    "            # Compile\n",
    "            model.compile(\n",
    "                optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy']\n",
    "            )\n",
    "\n",
    "            # Train\n",
    "            history = model.fit(\n",
    "                X_train_aug, y_train_aug,\n",
    "                validation_data=(X_val, y_val),\n",
    "                epochs=15,\n",
    "                batch_size=32,\n",
    "                callbacks=[early_stop]\n",
    "            )\n",
    "\n",
    "            # Save\n",
    "            label = (\n",
    "                f\"dense_nr={dense_nr}, \"\n",
    "                f\"activation={activation_name} \"\n",
    "            )\n",
    "            histories.append((label, history))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b562f42-07f0-4a71-9ff9-3b8d56db41f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, history in histories:\n",
    "    plt.figure(figsize=(40, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Loss '+label)\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss '+label)\n",
    "    plt.legend()\n",
    "    plt.title(\"Loss over Epochs\")\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title(\"Accuracy over Epochs\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d86f98b-4bd6-4540-b6a2-c2c2585790cc",
   "metadata": {},
   "source": [
    "Best performer: \n",
    "- Input → Conv2D(64) → MaxPool →\n",
    "- Conv2D(128) → MaxPool →\n",
    "- Conv2D(256) → MaxPool →\n",
    "- Dense(128) + Dropout → Dense(3, softmax)\n",
    "- Activation: LeakyReLU\n",
    "\n",
    "and balances speed, performance, and complexity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9863548-7ddb-4eeb-b412-f70ebe8dd832",
   "metadata": {},
   "source": [
    "Let us try fine-tuning the model, with changing some parameters and adding small changes that could improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8b25d9-1e6b-4132-a65c-f6cd558f354b",
   "metadata": {},
   "source": [
    "# 1. Small changes (different dropouts and initial kernels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089f64fa-044f-4074-8b77-f89849e21984",
   "metadata": {},
   "source": [
    "### Let us keep a history also for this model adjustments to see the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a32b540a-8981-4936-85f8-c384cc329199",
   "metadata": {},
   "outputs": [],
   "source": [
    "histories_leaky_128 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6874f88-5128-4391-9855-9ac92ccdebdd",
   "metadata": {},
   "source": [
    "And now train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743082ce-5674-4a4a-a2fe-20ae9bcc2d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with: initial_kernel=(3, 3), dropout=0.5\n",
      "Epoch 1/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.3580 - loss: 1.4246 - val_accuracy: 0.6068 - val_loss: 1.0028\n",
      "Epoch 2/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 2s/step - accuracy: 0.4897 - loss: 1.0140 - val_accuracy: 0.6154 - val_loss: 0.8748\n",
      "Epoch 3/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.6042 - loss: 0.8529 - val_accuracy: 0.6239 - val_loss: 0.8414\n",
      "Epoch 4/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.7346 - loss: 0.6558 - val_accuracy: 0.6923 - val_loss: 0.7376\n",
      "Epoch 5/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.8433 - loss: 0.4022 - val_accuracy: 0.6838 - val_loss: 0.8199\n",
      "Epoch 6/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 2s/step - accuracy: 0.9154 - loss: 0.2183 - val_accuracy: 0.6838 - val_loss: 0.9220\n",
      "Epoch 7/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.9530 - loss: 0.1212 - val_accuracy: 0.7094 - val_loss: 1.0271\n",
      "Epoch 8/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.9662 - loss: 0.0965 - val_accuracy: 0.7265 - val_loss: 1.4026\n",
      "Epoch 9/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.9693 - loss: 0.0843 - val_accuracy: 0.6838 - val_loss: 1.4339\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Training model with: initial_kernel=(3, 3), dropout=0.6\n",
      "Epoch 1/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 2s/step - accuracy: 0.3567 - loss: 1.5764 - val_accuracy: 0.5812 - val_loss: 1.0243\n",
      "Epoch 2/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.4465 - loss: 1.0413 - val_accuracy: 0.5812 - val_loss: 0.9871\n",
      "Epoch 3/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.4701 - loss: 1.0034 - val_accuracy: 0.5128 - val_loss: 0.9777\n",
      "Epoch 4/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 2s/step - accuracy: 0.5704 - loss: 0.8719 - val_accuracy: 0.6325 - val_loss: 0.8277\n",
      "Epoch 5/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.6898 - loss: 0.7317 - val_accuracy: 0.7094 - val_loss: 0.6934\n",
      "Epoch 6/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.7740 - loss: 0.5481 - val_accuracy: 0.6325 - val_loss: 0.7839\n",
      "Epoch 7/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 2s/step - accuracy: 0.8394 - loss: 0.4148 - val_accuracy: 0.6838 - val_loss: 0.8889\n",
      "Epoch 8/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.8496 - loss: 0.3435 - val_accuracy: 0.7094 - val_loss: 0.9217\n",
      "Epoch 9/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.9290 - loss: 0.1830 - val_accuracy: 0.7265 - val_loss: 1.0178\n",
      "Epoch 10/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.9557 - loss: 0.1215 - val_accuracy: 0.6496 - val_loss: 1.4035\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Training model with: initial_kernel=(3, 3), dropout=0.7\n",
      "Epoch 1/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.3442 - loss: 1.3606 - val_accuracy: 0.5983 - val_loss: 1.0047\n",
      "Epoch 2/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.4252 - loss: 1.0636 - val_accuracy: 0.5214 - val_loss: 0.9754\n",
      "Epoch 3/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.5084 - loss: 0.9789 - val_accuracy: 0.4957 - val_loss: 0.9386\n",
      "Epoch 4/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.6043 - loss: 0.8535 - val_accuracy: 0.6667 - val_loss: 0.7261\n",
      "Epoch 5/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.7137 - loss: 0.6593 - val_accuracy: 0.6581 - val_loss: 0.7508\n",
      "Epoch 6/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 2s/step - accuracy: 0.8142 - loss: 0.4636 - val_accuracy: 0.6923 - val_loss: 0.8032\n",
      "Epoch 7/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 2s/step - accuracy: 0.8856 - loss: 0.3000 - val_accuracy: 0.7009 - val_loss: 0.8326\n",
      "Epoch 8/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.9065 - loss: 0.2413 - val_accuracy: 0.7009 - val_loss: 0.8880\n",
      "Epoch 9/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.9227 - loss: 0.1923 - val_accuracy: 0.7094 - val_loss: 0.9350\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Training model with: initial_kernel=(5, 5), dropout=0.5\n",
      "Epoch 1/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.3592 - loss: 1.8768 - val_accuracy: 0.5470 - val_loss: 1.0715\n",
      "Epoch 2/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.3699 - loss: 1.0913 - val_accuracy: 0.3162 - val_loss: 1.0882\n",
      "Epoch 3/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.4798 - loss: 1.0297 - val_accuracy: 0.5556 - val_loss: 0.9263\n",
      "Epoch 4/15\n",
      "\u001b[1m44/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.5258 - loss: 0.9591"
     ]
    }
   ],
   "source": [
    "initial_kernels = [(3,3),(5,5)]\n",
    "dropouts = [0.5, 0.6, 0.7]\n",
    "\n",
    "\n",
    "for initial_kernel in initial_kernels:\n",
    "    for dropout in dropouts:\n",
    "        print(\n",
    "                f\"Training model with: \"\n",
    "                f\"initial_kernel={initial_kernel}, \"\n",
    "                f\"dropout={dropout}\"\n",
    "            )\n",
    "\n",
    "\n",
    "        # Model definition\n",
    "        model = Sequential([\n",
    "            Input(shape=(224, 224, 1)),\n",
    "            Conv2D(64, kernel_size=initial_kernel, activation=(LeakyReLU(negative_slope=0.01))),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "            Conv2D(128, kernel_size=(3,3), activation=(LeakyReLU(negative_slope=0.01))),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "            Conv2D(256, kernel_size=(3,3), activation=(LeakyReLU(negative_slope=0.01))),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "            Flatten(),\n",
    "            Dense(128, activation=(LeakyReLU(negative_slope=0.01))),\n",
    "            Dropout(dropout),\n",
    "            Dense(3, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        # Compile\n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        # Train\n",
    "        history = model.fit(\n",
    "            X_train_aug, y_train_aug,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=15,\n",
    "            batch_size=32,\n",
    "            callbacks=[early_stop]\n",
    "        )\n",
    "        \n",
    "        # Save\n",
    "        label = (\n",
    "            f\"initial_kernel={initial_kernel}, \"\n",
    "            f\"dropout={dropout}\"\n",
    "        )\n",
    "        histories_leaky_128.append((label, history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0895ac1-65ca-4285-9385-9743ebb712c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, history in histories_leaky_128:\n",
    "    plt.figure(figsize=(40, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Loss '+label)\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss '+label)\n",
    "    plt.legend()\n",
    "    plt.title(\"Loss over Epochs\")\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title(\"Accuracy over Epochs\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca1b59d5-613d-40a3-9160-e49f379331c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with: initial_kernel=(5, 5), dropout=0.5\n",
      "Epoch 1/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.3601 - loss: 1.4118 - val_accuracy: 0.5983 - val_loss: 0.9275\n",
      "Epoch 2/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.4848 - loss: 1.0198 - val_accuracy: 0.5897 - val_loss: 0.9260\n",
      "Epoch 3/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.6838 - loss: 0.7330 - val_accuracy: 0.6923 - val_loss: 0.7162\n",
      "Epoch 4/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 2s/step - accuracy: 0.8405 - loss: 0.4005 - val_accuracy: 0.7009 - val_loss: 0.7300\n",
      "Epoch 5/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.9090 - loss: 0.2593 - val_accuracy: 0.6923 - val_loss: 0.9693\n",
      "Epoch 6/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.9508 - loss: 0.1288 - val_accuracy: 0.7265 - val_loss: 1.1194\n",
      "Epoch 7/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.9721 - loss: 0.0824 - val_accuracy: 0.6752 - val_loss: 1.2722\n",
      "Epoch 8/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 2s/step - accuracy: 0.9737 - loss: 0.0614 - val_accuracy: 0.6581 - val_loss: 1.3565\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Training model with: initial_kernel=(5, 5), dropout=0.6\n",
      "Epoch 1/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.3475 - loss: 1.2329 - val_accuracy: 0.5641 - val_loss: 0.9840\n",
      "Epoch 2/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 2s/step - accuracy: 0.4285 - loss: 1.0747 - val_accuracy: 0.6068 - val_loss: 0.9374\n",
      "Epoch 3/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.5712 - loss: 0.9155 - val_accuracy: 0.6410 - val_loss: 0.7901\n",
      "Epoch 4/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.7128 - loss: 0.6933 - val_accuracy: 0.7179 - val_loss: 0.7705\n",
      "Epoch 5/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.8672 - loss: 0.3593 - val_accuracy: 0.7265 - val_loss: 0.7762\n",
      "Epoch 6/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.9171 - loss: 0.2184 - val_accuracy: 0.7179 - val_loss: 1.1824\n",
      "Epoch 7/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.9388 - loss: 0.1813 - val_accuracy: 0.7265 - val_loss: 1.0391\n",
      "Epoch 8/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.9590 - loss: 0.1149 - val_accuracy: 0.6838 - val_loss: 1.3868\n",
      "Epoch 9/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.9600 - loss: 0.1265 - val_accuracy: 0.7094 - val_loss: 1.3397\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Training model with: initial_kernel=(5, 5), dropout=0.7\n",
      "Epoch 1/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.3529 - loss: 1.6503 - val_accuracy: 0.6239 - val_loss: 1.0495\n",
      "Epoch 2/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 2s/step - accuracy: 0.4216 - loss: 1.0764 - val_accuracy: 0.6239 - val_loss: 0.9030\n",
      "Epoch 3/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.5189 - loss: 0.9808 - val_accuracy: 0.6068 - val_loss: 0.8526\n",
      "Epoch 4/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 2s/step - accuracy: 0.6005 - loss: 0.8803 - val_accuracy: 0.6752 - val_loss: 0.7485\n",
      "Epoch 5/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.6917 - loss: 0.7182 - val_accuracy: 0.7009 - val_loss: 0.7201\n",
      "Epoch 6/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.7798 - loss: 0.5058 - val_accuracy: 0.7094 - val_loss: 0.7306\n",
      "Epoch 7/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.8524 - loss: 0.3750 - val_accuracy: 0.7778 - val_loss: 0.6619\n",
      "Epoch 8/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.9282 - loss: 0.2348 - val_accuracy: 0.7265 - val_loss: 0.7439\n",
      "Epoch 9/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.9281 - loss: 0.1970 - val_accuracy: 0.7179 - val_loss: 0.8479\n",
      "Epoch 10/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 2s/step - accuracy: 0.9600 - loss: 0.1357 - val_accuracy: 0.7607 - val_loss: 0.7262\n",
      "Epoch 11/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.9513 - loss: 0.1312 - val_accuracy: 0.7436 - val_loss: 0.9205\n",
      "Epoch 12/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.9560 - loss: 0.1108 - val_accuracy: 0.7265 - val_loss: 0.9369\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n"
     ]
    }
   ],
   "source": [
    "initial_kernels = [(5,5)]\n",
    "dropouts = [0.5, 0.6, 0.7]\n",
    "\n",
    "\n",
    "for initial_kernel in initial_kernels:\n",
    "    for dropout in dropouts:\n",
    "        print(\n",
    "                f\"Training model with: \"\n",
    "                f\"initial_kernel={initial_kernel}, \"\n",
    "                f\"dropout={dropout}\"\n",
    "            )\n",
    "\n",
    "\n",
    "        # Model definition\n",
    "        model = Sequential([\n",
    "            Input(shape=(224, 224, 1)),\n",
    "            Conv2D(64, kernel_size=initial_kernel, activation=(LeakyReLU(negative_slope=0.01))),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "            Conv2D(128, kernel_size=(3,3), activation=(LeakyReLU(negative_slope=0.01))),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "            Conv2D(256, kernel_size=(3,3), activation=(LeakyReLU(negative_slope=0.01))),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "            Flatten(),\n",
    "            Dense(128, activation=(LeakyReLU(negative_slope=0.01))),\n",
    "            Dropout(dropout),\n",
    "            Dense(3, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        # Compile\n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        # Train\n",
    "        history = model.fit(\n",
    "            X_train_aug, y_train_aug,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=15,\n",
    "            batch_size=32,\n",
    "            callbacks=[early_stop]\n",
    "        )\n",
    "        \n",
    "        # Save\n",
    "        label = (\n",
    "            f\"initial_kernel={initial_kernel}, \"\n",
    "            f\"dropout={dropout}\"\n",
    "        )\n",
    "        histories_leaky_128.append((label, history))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd152b10-16d3-4009-bfbd-927d8852df23",
   "metadata": {},
   "source": [
    "We can see that Training model with: initial_kernel=(5, 5), dropout=0.7 provides the best results. Now let us try to improve it with some advanced techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10d3a80e-6bce-444f-a478-2ec589849446",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = Sequential([\n",
    "        Input(shape=(224, 224, 1)),\n",
    "        Conv2D(64, kernel_size=(5,5), activation=(LeakyReLU(negative_slope=0.01))),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "        Conv2D(128, kernel_size=(3,3), activation=(LeakyReLU(negative_slope=0.01))),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "        Conv2D(256, kernel_size=(3,3), activation=(LeakyReLU(negative_slope=0.01))),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "        Flatten(),\n",
    "        Dense(128, activation=(LeakyReLU(negative_slope=0.01))),\n",
    "        Dropout(0.7),\n",
    "        Dense(3, activation='softmax')\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18473038-f501-4821-870b-2f927beec01c",
   "metadata": {},
   "source": [
    "### Label Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5672cc75-cba3-4c71-bc77-f86222add7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "num_classes = 3  # Normal, Benign, Malignant\n",
    "label_smoothing = 0.1\n",
    "\n",
    "def smooth_labels(y, num_classes, smoothing=0.1):\n",
    "    \"\"\"\n",
    "    Converts sparse labels to smoothed one-hot vectors.\n",
    "    \"\"\"\n",
    "    y_one_hot = tf.one_hot(y, depth=num_classes)\n",
    "    smooth_positives = 1.0 - smoothing\n",
    "    smooth_negatives = smoothing / num_classes\n",
    "    y_smooth = y_one_hot * smooth_positives + smooth_negatives\n",
    "    return y_smooth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92dde81f-044c-4cb1-90fd-646ba538eaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_smooth = smooth_labels(y_train_aug, num_classes, label_smoothing)\n",
    "y_val_smooth = smooth_labels(y_val, num_classes, label_smoothing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f21269e5-930d-437e-9410-a4c88ae107d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.3641 - loss: 1.1715 - val_accuracy: 0.6068 - val_loss: 1.0505\n",
      "Epoch 2/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.4039 - loss: 1.0881 - val_accuracy: 0.5726 - val_loss: 1.0243\n",
      "Epoch 3/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.5091 - loss: 1.0043 - val_accuracy: 0.6325 - val_loss: 0.9147\n",
      "Epoch 4/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 2s/step - accuracy: 0.6075 - loss: 0.8995 - val_accuracy: 0.6410 - val_loss: 0.8625\n",
      "Epoch 5/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.7332 - loss: 0.7425 - val_accuracy: 0.6923 - val_loss: 0.7921\n",
      "Epoch 6/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.8464 - loss: 0.6143 - val_accuracy: 0.7094 - val_loss: 0.7730\n",
      "Epoch 7/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 2s/step - accuracy: 0.9061 - loss: 0.5217 - val_accuracy: 0.7350 - val_loss: 0.7665\n",
      "Epoch 8/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.9340 - loss: 0.4636 - val_accuracy: 0.7436 - val_loss: 0.7512\n",
      "Epoch 9/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 2s/step - accuracy: 0.9647 - loss: 0.4196 - val_accuracy: 0.7607 - val_loss: 0.7109\n",
      "Epoch 10/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.9750 - loss: 0.4030 - val_accuracy: 0.7692 - val_loss: 0.7254\n",
      "Epoch 11/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - accuracy: 0.9846 - loss: 0.3873 - val_accuracy: 0.7863 - val_loss: 0.7203\n",
      "Epoch 12/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 2s/step - accuracy: 0.9852 - loss: 0.3871 - val_accuracy: 0.7778 - val_loss: 0.7334\n",
      "Epoch 13/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.9869 - loss: 0.3760 - val_accuracy: 0.7949 - val_loss: 0.7224\n",
      "Epoch 14/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.9892 - loss: 0.3732 - val_accuracy: 0.8034 - val_loss: 0.7072\n",
      "Epoch 15/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - accuracy: 0.9920 - loss: 0.3663 - val_accuracy: 0.7949 - val_loss: 0.7252\n",
      "Epoch 16/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - accuracy: 0.9937 - loss: 0.3630 - val_accuracy: 0.7863 - val_loss: 0.6899\n",
      "Epoch 17/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - accuracy: 0.9932 - loss: 0.3669 - val_accuracy: 0.8034 - val_loss: 0.6929\n",
      "Epoch 18/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - accuracy: 0.9966 - loss: 0.3566 - val_accuracy: 0.7778 - val_loss: 0.6975\n",
      "Epoch 19/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - accuracy: 0.9960 - loss: 0.3580 - val_accuracy: 0.7949 - val_loss: 0.6938\n",
      "Epoch 20/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - accuracy: 0.9983 - loss: 0.3549 - val_accuracy: 0.7778 - val_loss: 0.7125\n",
      "Epoch 21/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - accuracy: 0.9977 - loss: 0.3513 - val_accuracy: 0.7778 - val_loss: 0.7050\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n"
     ]
    }
   ],
   "source": [
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "model_final.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "\n",
    "        \n",
    "# Train\n",
    "history = model_final.fit(\n",
    "        X_train_aug, y_train_smooth,\n",
    "        validation_data=(X_val, y_val_smooth),\n",
    "        epochs=30,\n",
    "        batch_size=32,\n",
    "        callbacks=[early_stop]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ccb0c4-065b-42eb-b851-d11e7a66f385",
   "metadata": {},
   "source": [
    "We can see that now we get 80% validation accuracy (around epoch 14)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3458256d-80eb-48bb-9715-3ecfaa77725e",
   "metadata": {},
   "source": [
    "### Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "416a5f62-eee8-418b-bdc2-f8e9ab6cc527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate scheduler\n",
    "reduce_lr_1 = ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr_2 = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=2,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr_3 = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.8,\n",
    "    patience=5,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "# Compile your model\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "model_final.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed33a55-925c-4835-bffa-38769999e9ac",
   "metadata": {},
   "source": [
    "## Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b8f8bb-0fae-4b2c-8978-99babebccb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - accuracy: 0.3350 - loss: 1.2126 - val_accuracy: 0.3761 - val_loss: 1.0995 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.4243 - loss: 1.0758 - val_accuracy: 0.5812 - val_loss: 0.9964 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - accuracy: 0.4886 - loss: 1.0258 - val_accuracy: 0.5385 - val_loss: 0.9800 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - accuracy: 0.5284 - loss: 0.9813 - val_accuracy: 0.6154 - val_loss: 0.8931 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.5722 - loss: 0.9361 - val_accuracy: 0.6667 - val_loss: 0.8288 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.6086 - loss: 0.8990 - val_accuracy: 0.5812 - val_loss: 0.8720 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - accuracy: 0.7184 - loss: 0.7789 - val_accuracy: 0.7094 - val_loss: 0.8158 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.7998 - loss: 0.6726 - val_accuracy: 0.6838 - val_loss: 0.7807 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.8709 - loss: 0.5782 - val_accuracy: 0.6838 - val_loss: 0.8272 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.9033 - loss: 0.5148 - val_accuracy: 0.7265 - val_loss: 0.7678 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.9317 - loss: 0.4724 - val_accuracy: 0.7350 - val_loss: 0.7629 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.9465 - loss: 0.4462 - val_accuracy: 0.6923 - val_loss: 0.7857 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.9630 - loss: 0.4260 - val_accuracy: 0.7436 - val_loss: 0.7919 - learning_rate: 0.0010\n",
      "Epoch 14/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.9630 - loss: 0.4281 - val_accuracy: 0.7094 - val_loss: 0.7561 - learning_rate: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 2s/step - accuracy: 0.9761 - loss: 0.4064 - val_accuracy: 0.7094 - val_loss: 0.7845 - learning_rate: 0.0010\n",
      "Epoch 16/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.9772 - loss: 0.4023 - val_accuracy: 0.7179 - val_loss: 0.7452 - learning_rate: 0.0010\n",
      "Epoch 17/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 2s/step - accuracy: 0.9818 - loss: 0.3948 - val_accuracy: 0.7094 - val_loss: 0.7609 - learning_rate: 0.0010\n",
      "Epoch 18/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.9926 - loss: 0.3814 - val_accuracy: 0.6923 - val_loss: 0.7879 - learning_rate: 0.0010\n",
      "Epoch 19/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 2s/step - accuracy: 0.9858 - loss: 0.3844 - val_accuracy: 0.7436 - val_loss: 0.7297 - learning_rate: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 2s/step - accuracy: 0.9892 - loss: 0.3768 - val_accuracy: 0.7436 - val_loss: 0.7213 - learning_rate: 0.0010\n",
      "Epoch 21/30\n",
      "\u001b[1m11/55\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:15\u001b[0m 2s/step - accuracy: 0.9950 - loss: 0.3719"
     ]
    }
   ],
   "source": [
    "# Train with callbacks\n",
    "history = model_final.fit(\n",
    "    X_train_aug, y_train_smooth,\n",
    "    validation_data=(X_val, y_val_smooth),\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop, reduce_lr_1]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0387e3-eb1b-4202-b1c9-3714514dd9df",
   "metadata": {},
   "source": [
    "## More aggressive decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d82ea63-6a38-4794-922e-202adf096662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.3601 - loss: 1.1581 - val_accuracy: 0.5043 - val_loss: 1.0302 - learning_rate: 0.0010\n",
      "Epoch 2/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.5023 - loss: 1.0226 - val_accuracy: 0.6239 - val_loss: 0.9245 - learning_rate: 0.0010\n",
      "Epoch 3/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.5779 - loss: 0.9304 - val_accuracy: 0.6410 - val_loss: 0.8633 - learning_rate: 0.0010\n",
      "Epoch 4/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.7190 - loss: 0.7739 - val_accuracy: 0.6752 - val_loss: 0.7874 - learning_rate: 0.0010\n",
      "Epoch 5/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.8163 - loss: 0.6353 - val_accuracy: 0.7350 - val_loss: 0.7268 - learning_rate: 0.0010\n",
      "Epoch 6/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.9016 - loss: 0.5226 - val_accuracy: 0.7265 - val_loss: 0.7259 - learning_rate: 0.0010\n",
      "Epoch 7/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.9443 - loss: 0.4561 - val_accuracy: 0.7521 - val_loss: 0.7183 - learning_rate: 0.0010\n",
      "Epoch 8/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.9738 - loss: 0.4175 - val_accuracy: 0.7692 - val_loss: 0.7062 - learning_rate: 0.0010\n",
      "Epoch 9/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.9733 - loss: 0.4105 - val_accuracy: 0.7607 - val_loss: 0.7434 - learning_rate: 0.0010\n",
      "Epoch 10/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9801 - loss: 0.3992\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.9812 - loss: 0.3977 - val_accuracy: 0.7692 - val_loss: 0.7156 - learning_rate: 0.0010\n",
      "Epoch 11/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.9875 - loss: 0.3762 - val_accuracy: 0.7692 - val_loss: 0.7140 - learning_rate: 2.0000e-04\n",
      "Epoch 12/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9918 - loss: 0.3665\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 2s/step - accuracy: 0.9909 - loss: 0.3703 - val_accuracy: 0.7863 - val_loss: 0.7068 - learning_rate: 2.0000e-04\n",
      "Epoch 13/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.9915 - loss: 0.3639 - val_accuracy: 0.7863 - val_loss: 0.7112 - learning_rate: 4.0000e-05\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n"
     ]
    }
   ],
   "source": [
    "# Train with callbacks\n",
    "history = model_final.fit(\n",
    "    X_train_aug, y_train_smooth,\n",
    "    validation_data=(X_val, y_val_smooth),\n",
    "    epochs=15,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop, reduce_lr_2]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11a39f7-6787-44ec-a641-7b4263b44e75",
   "metadata": {},
   "source": [
    "## More patient and less aggressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1439fcd-2e17-4767-9e3a-a1ada1b5b0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.3561 - loss: 1.2030 - val_accuracy: 0.5812 - val_loss: 1.0344 - learning_rate: 0.0010\n",
      "Epoch 2/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 2s/step - accuracy: 0.4448 - loss: 1.0660 - val_accuracy: 0.5214 - val_loss: 1.0102 - learning_rate: 0.0010\n",
      "Epoch 3/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.5205 - loss: 1.0060 - val_accuracy: 0.5897 - val_loss: 0.9342 - learning_rate: 0.0010\n",
      "Epoch 4/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.6297 - loss: 0.8932 - val_accuracy: 0.7094 - val_loss: 0.8048 - learning_rate: 0.0010\n",
      "Epoch 5/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.7509 - loss: 0.7395 - val_accuracy: 0.7265 - val_loss: 0.7655 - learning_rate: 0.0010\n",
      "Epoch 6/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.8515 - loss: 0.5978 - val_accuracy: 0.7009 - val_loss: 0.7585 - learning_rate: 0.0010\n",
      "Epoch 7/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.9027 - loss: 0.5183 - val_accuracy: 0.7094 - val_loss: 0.7777 - learning_rate: 0.0010\n",
      "Epoch 8/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.9408 - loss: 0.4619 - val_accuracy: 0.7265 - val_loss: 0.8088 - learning_rate: 0.0010\n",
      "Epoch 9/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.9670 - loss: 0.4339 - val_accuracy: 0.7094 - val_loss: 0.7596 - learning_rate: 0.0010\n",
      "Epoch 10/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.9642 - loss: 0.4177 - val_accuracy: 0.7179 - val_loss: 0.7857 - learning_rate: 0.0010\n",
      "Epoch 11/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9707 - loss: 0.4021\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.9704 - loss: 0.4042 - val_accuracy: 0.7179 - val_loss: 0.7852 - learning_rate: 0.0010\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n"
     ]
    }
   ],
   "source": [
    "# Train with callbacks\n",
    "history = model_final.fit(\n",
    "    X_train_aug, y_train_smooth,\n",
    "    validation_data=(X_val, y_val_smooth),\n",
    "    epochs=15,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop, reduce_lr_3]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde84446-e9a0-4a6d-a384-9451c9d817e3",
   "metadata": {},
   "source": [
    "### Cosine Annealing / Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f25d2a66-05a7-4703-b446-a4c36799a2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base setup\n",
    "lr_schedule_1 = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=1e-3,\n",
    "    decay_steps=15 * len(X_train_aug),  # for 15 epochs\n",
    "    alpha=1e-5\n",
    ")\n",
    "\n",
    "# Slower decay (higher alpha)\n",
    "lr_schedule_2 = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=1e-3,\n",
    "    decay_steps=15 * len(X_train_aug),\n",
    "    alpha=0.1  # final LR = 10% of initial\n",
    ")\n",
    "\n",
    "# Start slower but decay more\n",
    "lr_schedule_3 = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=5e-4,\n",
    "    decay_steps=15 * len(X_train_aug),\n",
    "    alpha=0.01\n",
    ")\n",
    "\n",
    "# Decay slower, over more steps\n",
    "lr_schedule_4 = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=1e-3,\n",
    "    decay_steps=30 * len(X_train_aug),  # longer decay\n",
    "    alpha=1e-5\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c17b112-ec5b-4121-8fcd-e6edb24385b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 2s/step - accuracy: 0.3549 - loss: 1.1699 - val_accuracy: 0.5043 - val_loss: 1.0628\n",
      "Epoch 2/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.4716 - loss: 1.0515 - val_accuracy: 0.6496 - val_loss: 0.9408\n",
      "Epoch 3/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.6172 - loss: 0.9038 - val_accuracy: 0.6496 - val_loss: 0.8963\n",
      "Epoch 4/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.7241 - loss: 0.7674 - val_accuracy: 0.6667 - val_loss: 0.8201\n",
      "Epoch 5/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.8356 - loss: 0.6191 - val_accuracy: 0.6923 - val_loss: 0.8383\n",
      "Epoch 6/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.9039 - loss: 0.5119 - val_accuracy: 0.7094 - val_loss: 0.7998\n",
      "Epoch 7/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.9499 - loss: 0.4494 - val_accuracy: 0.7350 - val_loss: 0.8360\n",
      "Epoch 8/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.9670 - loss: 0.4164 - val_accuracy: 0.7179 - val_loss: 0.7958\n",
      "Epoch 9/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 2s/step - accuracy: 0.9812 - loss: 0.3985 - val_accuracy: 0.7607 - val_loss: 0.7466\n",
      "Epoch 10/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.9790 - loss: 0.3909 - val_accuracy: 0.7436 - val_loss: 0.7325\n",
      "Epoch 11/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 2s/step - accuracy: 0.9937 - loss: 0.3735 - val_accuracy: 0.7009 - val_loss: 0.7636\n",
      "Epoch 12/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 2s/step - accuracy: 0.9920 - loss: 0.3704 - val_accuracy: 0.7265 - val_loss: 0.7845\n",
      "Epoch 13/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 2s/step - accuracy: 0.9937 - loss: 0.3646 - val_accuracy: 0.7179 - val_loss: 0.7542\n",
      "Epoch 14/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 2s/step - accuracy: 0.9954 - loss: 0.3589 - val_accuracy: 0.7436 - val_loss: 0.7653\n",
      "Epoch 15/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.9926 - loss: 0.3591 - val_accuracy: 0.7179 - val_loss: 0.7291\n",
      "Restoring model weights from the end of the best epoch: 15.\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule_1)\n",
    "\n",
    "# Compile your model\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "model_final.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    " \n",
    "# Train\n",
    "history = model_final.fit(\n",
    "    X_train_aug, y_train_smooth,\n",
    "    validation_data=(X_val, y_val_smooth),\n",
    "    epochs=15,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a2731e5-5bb3-4cf0-8b72-e6c0351e9498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.3589 - loss: 1.1834 - val_accuracy: 0.2735 - val_loss: 1.0705\n",
      "Epoch 2/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.4829 - loss: 1.0230 - val_accuracy: 0.6752 - val_loss: 0.8803\n",
      "Epoch 3/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.6200 - loss: 0.9003 - val_accuracy: 0.6410 - val_loss: 0.8517\n",
      "Epoch 4/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 2s/step - accuracy: 0.7139 - loss: 0.7829 - val_accuracy: 0.6496 - val_loss: 0.8269\n",
      "Epoch 5/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.7850 - loss: 0.6825 - val_accuracy: 0.6667 - val_loss: 0.8458\n",
      "Epoch 6/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.8515 - loss: 0.5893 - val_accuracy: 0.6838 - val_loss: 0.8275\n",
      "Epoch 7/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 2s/step - accuracy: 0.9039 - loss: 0.5190 - val_accuracy: 0.7094 - val_loss: 0.7659\n",
      "Epoch 8/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.9357 - loss: 0.4691 - val_accuracy: 0.7179 - val_loss: 0.7475\n",
      "Epoch 9/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 2s/step - accuracy: 0.9590 - loss: 0.4381 - val_accuracy: 0.7094 - val_loss: 0.7675\n",
      "Epoch 10/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 2s/step - accuracy: 0.9590 - loss: 0.4275 - val_accuracy: 0.7009 - val_loss: 0.7548\n",
      "Epoch 11/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.9716 - loss: 0.4136 - val_accuracy: 0.7094 - val_loss: 0.7602\n",
      "Epoch 12/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 2s/step - accuracy: 0.9841 - loss: 0.3950 - val_accuracy: 0.7009 - val_loss: 0.7603\n",
      "Epoch 13/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 2s/step - accuracy: 0.9869 - loss: 0.3891 - val_accuracy: 0.7350 - val_loss: 0.7584\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule_2)\n",
    "\n",
    "# Compile your model\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "model_final.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    " \n",
    "# Train\n",
    "history = model_final.fit(\n",
    "    X_train_aug, y_train_smooth,\n",
    "    validation_data=(X_val, y_val_smooth),\n",
    "    epochs=15,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb44dfa-1df4-4000-8902-53b8b7964c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.3447 - loss: 1.1633 - val_accuracy: 0.5556 - val_loss: 1.0616\n",
      "Epoch 2/15\n",
      "\u001b[1m 7/55\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:20\u001b[0m 2s/step - accuracy: 0.3380 - loss: 1.1020"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule_3)\n",
    "\n",
    "# Compile your model\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "model_final.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    " \n",
    "# Train\n",
    "history = model_final.fit(\n",
    "    X_train_aug, y_train_smooth,\n",
    "    validation_data=(X_val, y_val_smooth),\n",
    "    epochs=15,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d93f9861-f0a2-4b02-9ed1-f283d9cd8311",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mlr_schedule_4)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Compile your model\u001b[39;00m\n\u001b[0;32m      4\u001b[0m loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule_4)\n",
    "\n",
    "# Compile your model\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "model_final.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    " \n",
    "# Train\n",
    "history = model_final.fit(\n",
    "    X_train_aug, y_train_smooth,\n",
    "    validation_data=(X_val, y_val_smooth),\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6410ca09-e342-41e0-9c9f-b1b4ab0d1576",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
