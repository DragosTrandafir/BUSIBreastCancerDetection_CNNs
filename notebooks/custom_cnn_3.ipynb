{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aadb85c5-5d1e-4d24-80b6-e4353e413c78",
   "metadata": {},
   "source": [
    "# Custom CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df1f0d67-2fda-4ae1-a81b-6cd1eb104f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 210 images and 211 masks in malignant folder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing malignant images: 100%|███████████████████████████████████████████████████| 210/210 [00:02<00:00, 95.91it/s]\n",
      "Processing malignant masks: 100%|███████████████████████████████████████████████████| 211/211 [00:00<00:00, 571.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 133 images and 133 masks in normal folder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing normal images: 100%|██████████████████████████████████████████████████████| 133/133 [00:01<00:00, 89.38it/s]\n",
      "Processing normal masks: 100%|██████████████████████████████████████████████████████| 133/133 [00:00<00:00, 262.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 437 images and 454 masks in benign folder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing benign images: 100%|██████████████████████████████████████████████████████| 437/437 [00:04<00:00, 94.66it/s]\n",
      "Processing benign masks: 100%|██████████████████████████████████████████████████████| 454/454 [00:00<00:00, 604.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined 2 masks for malignant (53).png\n",
      "Combined 2 masks for benign (100).png\n",
      "Combined 2 masks for benign (163).png\n",
      "Combined 2 masks for benign (173).png\n",
      "Combined 2 masks for benign (181).png\n",
      "Combined 3 masks for benign (195).png\n",
      "Combined 2 masks for benign (25).png\n",
      "Combined 2 masks for benign (315).png\n",
      "Combined 2 masks for benign (346).png\n",
      "Combined 2 masks for benign (4).png\n",
      "Combined 2 masks for benign (424).png\n",
      "Combined 2 masks for benign (54).png\n",
      "Combined 2 masks for benign (58).png\n",
      "Combined 2 masks for benign (83).png\n",
      "Combined 2 masks for benign (92).png\n",
      "Combined 2 masks for benign (93).png\n",
      "Combined 2 masks for benign (98).png\n",
      "Dataset shape: (780, 224, 224, 1)\n",
      "Masks shape: (780, 224, 224, 1)\n",
      "Labels shape: (780,)\n",
      "Class distribution: Normal: 133, Benign: 437, Malignant: 210\n",
      "Training set sizes: X_train: (546, 224, 224, 1), y_train: (546,), masks: (780, 224, 224, 1)\n",
      "Augmented training set sizes: X_aug: (1758, 224, 224, 1), y_aug: (1758,), masks: (1758, 224, 224, 1)\n",
      "Validation set sizes: X_val: (117, 224, 224, 1), y_val: (117,), masks: (117, 224, 224, 1)\n",
      "Test set sizes: X_test: (117, 224, 224, 1), y_test: (117,), masks: (117, 224, 224, 1)\n",
      "Augmented Normal: 558 samples\n",
      "Augmented Benign: 612 samples\n",
      "Augmented Malignant: 588 samples\n",
      "Augmented images saved to: C:/Users/DragosTrandafiri/BreastCancer_CNN/data/processed/busi/processed_images_augmented/X\n"
     ]
    }
   ],
   "source": [
    "# Run the previous notebook to load all its classes and functions\n",
    "%run busi_augmentation_2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eb4f114-0c17-496d-8fe3-67a6deddc5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, LeakyReLU, BatchNormalization, Conv2D, MaxPooling2D, Flatten,  Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist, cifar10\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a935f603-5aa8-4969-be7e-85a0352fde43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1758, 224, 224, 1)\n",
      "(1758,)\n",
      "(1758, 224, 224, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_aug.shape)\n",
    "print(y_aug.shape)\n",
    "print(masks_aug.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3dff71-c4f4-4f64-a31b-441c6be23b99",
   "metadata": {},
   "source": [
    "# Apply MINMAX normalization (suitable for CNNs custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e558a08-7d48-4a4e-b7ae-7365b111ccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "X_train_aug = X_aug.astype(\"float32\") / 255.0\n",
    "masks_train_aug = masks_aug.astype(\"float32\") / 255.0\n",
    "y_train_aug = y_aug\n",
    "\n",
    "# Test\n",
    "X_test = X_test.astype(\"float32\") / 255.0\n",
    "masks_test = masks_test.astype(\"float32\") / 255.0\n",
    "y_test = y_test\n",
    "\n",
    "# Validation\n",
    "X_val = X_val.astype(\"float32\") / 255.0\n",
    "masks_val = masks_val.astype(\"float32\") / 255.0\n",
    "y_val = y_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6718b1b5-17af-4bf6-ba68-afbe2db715a3",
   "metadata": {},
   "source": [
    "# 1. Model from article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bdd82ad-4cc8-463f-bc16-151d5ea182c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    # Input layer (grayscale images 224x224x1)\n",
    "    Input(shape=(224, 224, 1)),\n",
    "\n",
    "    # Convolutional layer: 20 filters, kernel size 5x5\n",
    "    Conv2D(20, (5, 5), padding=\"same\"),\n",
    "    \n",
    "    # Batch Normalization (20 channels)\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    # ReLU activation\n",
    "    Activation(\"relu\"),\n",
    "    \n",
    "    # MaxPooling\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Flatten before fully connected\n",
    "    Flatten(),\n",
    "    \n",
    "    # Fully connected layer (let’s use 128 units)\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    \n",
    "    # Dropout 50%\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    # Output layer with 3 classes\n",
    "    Dense(3, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34089342-0e52-4898-bb3c-bc3b56033908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 662ms/step - accuracy: 0.3490 - loss: 45.4109 - val_accuracy: 0.2735 - val_loss: 1.0989\n",
      "Epoch 2/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 645ms/step - accuracy: 0.3522 - loss: 1.1493 - val_accuracy: 0.5641 - val_loss: 1.0962\n",
      "Epoch 3/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 651ms/step - accuracy: 0.3508 - loss: 1.0980 - val_accuracy: 0.5556 - val_loss: 1.0943\n",
      "Epoch 4/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 648ms/step - accuracy: 0.3435 - loss: 1.0986 - val_accuracy: 0.5556 - val_loss: 1.0932\n",
      "Epoch 5/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 647ms/step - accuracy: 0.3555 - loss: 1.0973 - val_accuracy: 0.5556 - val_loss: 1.0898\n",
      "Epoch 6/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 644ms/step - accuracy: 0.3487 - loss: 1.0981 - val_accuracy: 0.5556 - val_loss: 1.0892\n",
      "Epoch 7/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 646ms/step - accuracy: 0.3493 - loss: 1.0978 - val_accuracy: 0.5556 - val_loss: 1.0876\n",
      "Epoch 8/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 643ms/step - accuracy: 0.3609 - loss: 1.0974 - val_accuracy: 0.5556 - val_loss: 1.0866\n",
      "Epoch 9/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 645ms/step - accuracy: 0.3349 - loss: 1.0988 - val_accuracy: 0.5556 - val_loss: 1.0865\n",
      "Epoch 10/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 646ms/step - accuracy: 0.3300 - loss: 1.0956 - val_accuracy: 0.5556 - val_loss: 1.0854\n",
      "Epoch 11/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 643ms/step - accuracy: 0.3428 - loss: 1.0985 - val_accuracy: 0.5556 - val_loss: 1.0844\n",
      "Epoch 12/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 648ms/step - accuracy: 0.3459 - loss: 1.0981 - val_accuracy: 0.5556 - val_loss: 1.0835\n",
      "Epoch 13/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 643ms/step - accuracy: 0.3606 - loss: 1.0967 - val_accuracy: 0.5556 - val_loss: 1.0826\n",
      "Epoch 14/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 645ms/step - accuracy: 0.3570 - loss: 1.0962 - val_accuracy: 0.5556 - val_loss: 1.0830\n",
      "Epoch 15/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 646ms/step - accuracy: 0.3579 - loss: 1.0960 - val_accuracy: 0.5556 - val_loss: 1.0825\n",
      "Restoring model weights from the end of the best epoch: 15.\n"
     ]
    }
   ],
   "source": [
    "# Compile\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    X_train_aug, y_train_aug,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=15,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# Save\n",
    "label = (\n",
    "    f\"custom_CNN_from_Convolutionalneuralnetwork-basedmodelsfordiagnosisofbreast\"\n",
    ")\n",
    "histories.append((label, history))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fb2465-e414-4ecd-b6e3-6bcd62c2ffe2",
   "metadata": {},
   "source": [
    "### Apply early stopping to save time & avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bfb8ce8-029b-4678-9c93-d5ff951fef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping\n",
    "early_stop = EarlyStopping(patience=5, restore_best_weights=True,monitor='val_loss', verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c324caf8-4fd9-4fc2-b1ff-45071c2bae4c",
   "metadata": {},
   "source": [
    "# Custom CNNs (initial trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab72ade7-4140-436d-afe6-e5b12b42c173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with: activation=relu, dense_layer=32\n",
      "Epoch 1/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 535ms/step - accuracy: 0.3700 - loss: 1.2998 - val_accuracy: 0.5812 - val_loss: 0.9757\n",
      "Epoch 2/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 523ms/step - accuracy: 0.5673 - loss: 0.9334 - val_accuracy: 0.5726 - val_loss: 0.8272\n",
      "Epoch 3/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 522ms/step - accuracy: 0.7537 - loss: 0.6324 - val_accuracy: 0.6496 - val_loss: 0.7889\n",
      "Epoch 4/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 524ms/step - accuracy: 0.8248 - loss: 0.4505 - val_accuracy: 0.5983 - val_loss: 0.9415\n",
      "Epoch 5/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 525ms/step - accuracy: 0.9171 - loss: 0.2377 - val_accuracy: 0.6410 - val_loss: 1.1813\n",
      "Epoch 6/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 525ms/step - accuracy: 0.9516 - loss: 0.1418 - val_accuracy: 0.6667 - val_loss: 1.2107\n",
      "Epoch 7/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 527ms/step - accuracy: 0.9546 - loss: 0.1256 - val_accuracy: 0.6325 - val_loss: 1.5552\n",
      "Epoch 8/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 534ms/step - accuracy: 0.9732 - loss: 0.0851 - val_accuracy: 0.6239 - val_loss: 1.4327\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Training model with: activation=leakyrelu, dense_layer=32\n",
      "Epoch 1/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 579ms/step - accuracy: 0.3531 - loss: 1.4614 - val_accuracy: 0.5470 - val_loss: 0.9782\n",
      "Epoch 2/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 579ms/step - accuracy: 0.5347 - loss: 0.9348 - val_accuracy: 0.6325 - val_loss: 0.8124\n",
      "Epoch 3/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 574ms/step - accuracy: 0.7120 - loss: 0.6754 - val_accuracy: 0.6923 - val_loss: 0.7111\n",
      "Epoch 4/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 583ms/step - accuracy: 0.8638 - loss: 0.3726 - val_accuracy: 0.7436 - val_loss: 0.7834\n",
      "Epoch 5/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 594ms/step - accuracy: 0.9300 - loss: 0.1989 - val_accuracy: 0.7265 - val_loss: 1.0464\n",
      "Epoch 6/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 607ms/step - accuracy: 0.9587 - loss: 0.1150 - val_accuracy: 0.7094 - val_loss: 0.8067\n",
      "Epoch 7/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 599ms/step - accuracy: 0.9813 - loss: 0.0704 - val_accuracy: 0.7179 - val_loss: 1.1487\n",
      "Epoch 8/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 605ms/step - accuracy: 0.9826 - loss: 0.0489 - val_accuracy: 0.7436 - val_loss: 1.1476\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Training model with: activation=relu, dense_layer=64\n",
      "Epoch 1/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2s/step - accuracy: 0.3681 - loss: 1.2456 - val_accuracy: 0.6239 - val_loss: 0.9371\n",
      "Epoch 2/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 2s/step - accuracy: 0.5176 - loss: 0.9670 - val_accuracy: 0.5897 - val_loss: 0.8355\n",
      "Epoch 3/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2s/step - accuracy: 0.7158 - loss: 0.7031 - val_accuracy: 0.6325 - val_loss: 0.7753\n",
      "Epoch 4/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2s/step - accuracy: 0.8066 - loss: 0.4889 - val_accuracy: 0.7094 - val_loss: 0.8546\n",
      "Epoch 5/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2s/step - accuracy: 0.9193 - loss: 0.2404 - val_accuracy: 0.6752 - val_loss: 0.9895\n",
      "Epoch 6/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 2s/step - accuracy: 0.9549 - loss: 0.1346 - val_accuracy: 0.6752 - val_loss: 1.0973\n",
      "Epoch 7/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 2s/step - accuracy: 0.9642 - loss: 0.1017 - val_accuracy: 0.5897 - val_loss: 1.3909\n",
      "Epoch 8/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.9759 - loss: 0.0764 - val_accuracy: 0.7009 - val_loss: 1.2061\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Training model with: activation=leakyrelu, dense_layer=64\n",
      "Epoch 1/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - accuracy: 0.3572 - loss: 1.5244 - val_accuracy: 0.5812 - val_loss: 1.0812\n",
      "Epoch 2/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 2s/step - accuracy: 0.4951 - loss: 1.0253 - val_accuracy: 0.5897 - val_loss: 0.8605\n",
      "Epoch 3/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 2s/step - accuracy: 0.5465 - loss: 0.9090 - val_accuracy: 0.6410 - val_loss: 0.7913\n",
      "Epoch 4/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 2s/step - accuracy: 0.7181 - loss: 0.6834 - val_accuracy: 0.6581 - val_loss: 0.7313\n",
      "Epoch 5/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.8263 - loss: 0.4176 - val_accuracy: 0.7350 - val_loss: 0.6647\n",
      "Epoch 6/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.9298 - loss: 0.1881 - val_accuracy: 0.7436 - val_loss: 0.7912\n",
      "Epoch 7/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.9614 - loss: 0.1060 - val_accuracy: 0.7179 - val_loss: 0.8026\n",
      "Epoch 8/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.9809 - loss: 0.0862 - val_accuracy: 0.7521 - val_loss: 0.9294\n",
      "Epoch 9/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.9866 - loss: 0.0452 - val_accuracy: 0.7265 - val_loss: 1.1233\n",
      "Epoch 10/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 2s/step - accuracy: 0.9868 - loss: 0.0429 - val_accuracy: 0.7265 - val_loss: 0.8742\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Training model with: activation=relu, dense_layer=128\n",
      "Epoch 1/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 6s/step - accuracy: 0.3204 - loss: 2.0159 - val_accuracy: 0.5214 - val_loss: 1.0752\n",
      "Epoch 2/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 6s/step - accuracy: 0.4609 - loss: 1.0526 - val_accuracy: 0.6068 - val_loss: 0.8927\n",
      "Epoch 3/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 5s/step - accuracy: 0.5792 - loss: 0.8896 - val_accuracy: 0.6239 - val_loss: 0.8489\n",
      "Epoch 4/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 5s/step - accuracy: 0.7285 - loss: 0.6546 - val_accuracy: 0.6068 - val_loss: 0.8240\n",
      "Epoch 5/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 5s/step - accuracy: 0.7921 - loss: 0.5257 - val_accuracy: 0.6496 - val_loss: 0.8253\n",
      "Epoch 6/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 5s/step - accuracy: 0.8775 - loss: 0.3153 - val_accuracy: 0.6496 - val_loss: 0.9892\n",
      "Epoch 7/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 5s/step - accuracy: 0.9370 - loss: 0.1807 - val_accuracy: 0.6838 - val_loss: 0.9131\n",
      "Epoch 8/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 5s/step - accuracy: 0.9357 - loss: 0.1641 - val_accuracy: 0.6752 - val_loss: 1.0761\n",
      "Epoch 9/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 6s/step - accuracy: 0.9466 - loss: 0.1211 - val_accuracy: 0.6752 - val_loss: 1.2989\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Training model with: activation=leakyrelu, dense_layer=128\n",
      "Epoch 1/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 6s/step - accuracy: 0.3490 - loss: 1.6764 - val_accuracy: 0.5385 - val_loss: 0.9932\n",
      "Epoch 2/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 6s/step - accuracy: 0.4576 - loss: 1.0467 - val_accuracy: 0.5556 - val_loss: 1.0337\n",
      "Epoch 3/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 6s/step - accuracy: 0.6059 - loss: 0.8815 - val_accuracy: 0.6325 - val_loss: 0.7720\n",
      "Epoch 4/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 6s/step - accuracy: 0.7408 - loss: 0.5942 - val_accuracy: 0.7179 - val_loss: 0.6186\n",
      "Epoch 5/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 6s/step - accuracy: 0.8465 - loss: 0.3992 - val_accuracy: 0.7350 - val_loss: 0.6264\n",
      "Epoch 6/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 6s/step - accuracy: 0.9184 - loss: 0.2283 - val_accuracy: 0.7521 - val_loss: 0.8018\n",
      "Epoch 7/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 6s/step - accuracy: 0.9556 - loss: 0.1475 - val_accuracy: 0.6923 - val_loss: 0.8326\n",
      "Epoch 8/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 6s/step - accuracy: 0.9681 - loss: 0.0896 - val_accuracy: 0.7607 - val_loss: 1.0658\n",
      "Epoch 9/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 6s/step - accuracy: 0.9733 - loss: 0.0723 - val_accuracy: 0.7094 - val_loss: 1.1249\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter options\n",
    "\n",
    "activations = [\n",
    "    (\"relu\", \"relu\"),\n",
    "    (\"leakyrelu\", LeakyReLU(negative_slope=0.01))\n",
    "]\n",
    "dense_layers =[32, 64, 128]\n",
    "\n",
    "\n",
    "histories = []\n",
    "\n",
    "\n",
    "for dense_nr in dense_layers:\n",
    "    for activation_name, activation_fn in activations:\n",
    "            print(\n",
    "                f\"Training model with: \"\n",
    "                f\"activation={activation_name}, \"\n",
    "                f\"dense_layer={dense_nr}\"\n",
    "            )\n",
    "\n",
    "\n",
    "            # Model definition\n",
    "            model = Sequential([\n",
    "                Input(shape=(224, 224, 1)),\n",
    "                Conv2D(dense_nr, kernel_size=(3,3), activation=activation_fn),\n",
    "                MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "                Conv2D(dense_nr*2, kernel_size=(3,3), activation=activation_fn),\n",
    "                MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "                Conv2D(dense_nr*4, kernel_size=(3,3), activation=activation_fn),\n",
    "                MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "                Flatten(),\n",
    "                Dense(128, activation=activation_fn),\n",
    "                Dropout(0.5),\n",
    "                Dense(3, activation='softmax')\n",
    "            ])\n",
    "\n",
    "            # Compile\n",
    "            model.compile(\n",
    "                optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy']\n",
    "            )\n",
    "\n",
    "            # Train\n",
    "            history = model.fit(\n",
    "                X_train_aug, y_train_aug,\n",
    "                validation_data=(X_val, y_val),\n",
    "                epochs=15,\n",
    "                batch_size=32,\n",
    "                callbacks=[early_stop]\n",
    "            )\n",
    "\n",
    "            # Save\n",
    "            label = (\n",
    "                f\"dense_nr={dense_nr}, \"\n",
    "                f\"activation={activation_name} \"\n",
    "            )\n",
    "            histories.append((label, history))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d86f98b-4bd6-4540-b6a2-c2c2585790cc",
   "metadata": {},
   "source": [
    "Best performer: \n",
    "- Input → Conv2D(64) → MaxPool →\n",
    "- Conv2D(128) → MaxPool →\n",
    "- Conv2D(256) → MaxPool →\n",
    "- Dense(128) + Dropout → Dense(3, softmax)\n",
    "- Activation: LeakyReLU\n",
    "\n",
    "and balances speed, performance, and complexity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9863548-7ddb-4eeb-b412-f70ebe8dd832",
   "metadata": {},
   "source": [
    "Let us try fine-tuning the model, with changing some parameters and adding small changes that could improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8b25d9-1e6b-4132-a65c-f6cd558f354b",
   "metadata": {},
   "source": [
    "# 1. Small changes (different dropouts and initial kernels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089f64fa-044f-4074-8b77-f89849e21984",
   "metadata": {},
   "source": [
    "### Let us keep a history also for this model adjustments to see the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a32b540a-8981-4936-85f8-c384cc329199",
   "metadata": {},
   "outputs": [],
   "source": [
    "histories_leaky_128 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6874f88-5128-4391-9855-9ac92ccdebdd",
   "metadata": {},
   "source": [
    "And now train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743082ce-5674-4a4a-a2fe-20ae9bcc2d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with: initial_kernel=(3, 3), dropout=0.5\n",
      "Epoch 1/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.3580 - loss: 1.4246 - val_accuracy: 0.6068 - val_loss: 1.0028\n",
      "Epoch 2/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 2s/step - accuracy: 0.4897 - loss: 1.0140 - val_accuracy: 0.6154 - val_loss: 0.8748\n",
      "Epoch 3/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.6042 - loss: 0.8529 - val_accuracy: 0.6239 - val_loss: 0.8414\n",
      "Epoch 4/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.7346 - loss: 0.6558 - val_accuracy: 0.6923 - val_loss: 0.7376\n",
      "Epoch 5/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.8433 - loss: 0.4022 - val_accuracy: 0.6838 - val_loss: 0.8199\n",
      "Epoch 6/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 2s/step - accuracy: 0.9154 - loss: 0.2183 - val_accuracy: 0.6838 - val_loss: 0.9220\n",
      "Epoch 7/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.9530 - loss: 0.1212 - val_accuracy: 0.7094 - val_loss: 1.0271\n",
      "Epoch 8/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.9662 - loss: 0.0965 - val_accuracy: 0.7265 - val_loss: 1.4026\n",
      "Epoch 9/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.9693 - loss: 0.0843 - val_accuracy: 0.6838 - val_loss: 1.4339\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Training model with: initial_kernel=(3, 3), dropout=0.6\n",
      "Epoch 1/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 2s/step - accuracy: 0.3567 - loss: 1.5764 - val_accuracy: 0.5812 - val_loss: 1.0243\n",
      "Epoch 2/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.4465 - loss: 1.0413 - val_accuracy: 0.5812 - val_loss: 0.9871\n",
      "Epoch 3/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.4701 - loss: 1.0034 - val_accuracy: 0.5128 - val_loss: 0.9777\n",
      "Epoch 4/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 2s/step - accuracy: 0.5704 - loss: 0.8719 - val_accuracy: 0.6325 - val_loss: 0.8277\n",
      "Epoch 5/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.6898 - loss: 0.7317 - val_accuracy: 0.7094 - val_loss: 0.6934\n",
      "Epoch 6/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.7740 - loss: 0.5481 - val_accuracy: 0.6325 - val_loss: 0.7839\n",
      "Epoch 7/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 2s/step - accuracy: 0.8394 - loss: 0.4148 - val_accuracy: 0.6838 - val_loss: 0.8889\n",
      "Epoch 8/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.8496 - loss: 0.3435 - val_accuracy: 0.7094 - val_loss: 0.9217\n",
      "Epoch 9/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.9290 - loss: 0.1830 - val_accuracy: 0.7265 - val_loss: 1.0178\n",
      "Epoch 10/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.9557 - loss: 0.1215 - val_accuracy: 0.6496 - val_loss: 1.4035\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Training model with: initial_kernel=(3, 3), dropout=0.7\n",
      "Epoch 1/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.3442 - loss: 1.3606 - val_accuracy: 0.5983 - val_loss: 1.0047\n",
      "Epoch 2/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.4252 - loss: 1.0636 - val_accuracy: 0.5214 - val_loss: 0.9754\n",
      "Epoch 3/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.5084 - loss: 0.9789 - val_accuracy: 0.4957 - val_loss: 0.9386\n",
      "Epoch 4/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.6043 - loss: 0.8535 - val_accuracy: 0.6667 - val_loss: 0.7261\n",
      "Epoch 5/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.7137 - loss: 0.6593 - val_accuracy: 0.6581 - val_loss: 0.7508\n",
      "Epoch 6/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 2s/step - accuracy: 0.8142 - loss: 0.4636 - val_accuracy: 0.6923 - val_loss: 0.8032\n",
      "Epoch 7/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 2s/step - accuracy: 0.8856 - loss: 0.3000 - val_accuracy: 0.7009 - val_loss: 0.8326\n",
      "Epoch 8/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.9065 - loss: 0.2413 - val_accuracy: 0.7009 - val_loss: 0.8880\n",
      "Epoch 9/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.9227 - loss: 0.1923 - val_accuracy: 0.7094 - val_loss: 0.9350\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Training model with: initial_kernel=(5, 5), dropout=0.5\n",
      "Epoch 1/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.3592 - loss: 1.8768 - val_accuracy: 0.5470 - val_loss: 1.0715\n",
      "Epoch 2/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.3699 - loss: 1.0913 - val_accuracy: 0.3162 - val_loss: 1.0882\n",
      "Epoch 3/15\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.4798 - loss: 1.0297 - val_accuracy: 0.5556 - val_loss: 0.9263\n",
      "Epoch 4/15\n",
      "\u001b[1m44/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.5258 - loss: 0.9591"
     ]
    }
   ],
   "source": [
    "initial_kernels = [(3,3),(5,5)]\n",
    "dropouts = [0.5, 0.6, 0.7]\n",
    "\n",
    "\n",
    "for initial_kernel in initial_kernels:\n",
    "    for dropout in dropouts:\n",
    "        print(\n",
    "                f\"Training model with: \"\n",
    "                f\"initial_kernel={initial_kernel}, \"\n",
    "                f\"dropout={dropout}\"\n",
    "            )\n",
    "\n",
    "\n",
    "        # Model definition\n",
    "        model = Sequential([\n",
    "            Input(shape=(224, 224, 1)),\n",
    "            Conv2D(64, kernel_size=initial_kernel, activation=(LeakyReLU(negative_slope=0.01))),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "            Conv2D(128, kernel_size=(3,3), activation=(LeakyReLU(negative_slope=0.01))),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "            Conv2D(256, kernel_size=(3,3), activation=(LeakyReLU(negative_slope=0.01))),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "            Flatten(),\n",
    "            Dense(128, activation=(LeakyReLU(negative_slope=0.01))),\n",
    "            Dropout(dropout),\n",
    "            Dense(3, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        # Compile\n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        # Train\n",
    "        history = model.fit(\n",
    "            X_train_aug, y_train_aug,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=15,\n",
    "            batch_size=32,\n",
    "            callbacks=[early_stop]\n",
    "        )\n",
    "        \n",
    "        # Save\n",
    "        label = (\n",
    "            f\"initial_kernel={initial_kernel}, \"\n",
    "            f\"dropout={dropout}\"\n",
    "        )\n",
    "        histories_leaky_128.append((label, history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1b59d5-613d-40a3-9160-e49f379331c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_kernels = [(5,5)]\n",
    "dropouts = [0.5, 0.6, 0.7]\n",
    "\n",
    "\n",
    "for initial_kernel in initial_kernels:\n",
    "    for dropout in dropouts:\n",
    "        print(\n",
    "                f\"Training model with: \"\n",
    "                f\"initial_kernel={initial_kernel}, \"\n",
    "                f\"dropout={dropout}\"\n",
    "            )\n",
    "\n",
    "\n",
    "        # Model definition\n",
    "        model = Sequential([\n",
    "            Input(shape=(224, 224, 1)),\n",
    "            Conv2D(64, kernel_size=initial_kernel, activation=(LeakyReLU(negative_slope=0.01))),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "            Conv2D(128, kernel_size=(3,3), activation=(LeakyReLU(negative_slope=0.01))),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "            Conv2D(256, kernel_size=(3,3), activation=(LeakyReLU(negative_slope=0.01))),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "            Flatten(),\n",
    "            Dense(128, activation=(LeakyReLU(negative_slope=0.01))),\n",
    "            Dropout(dropout),\n",
    "            Dense(3, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        # Compile\n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        # Train\n",
    "        history = model.fit(\n",
    "            X_train_aug, y_train_aug,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=15,\n",
    "            batch_size=32,\n",
    "            callbacks=[early_stop]\n",
    "        )\n",
    "        \n",
    "        # Save\n",
    "        label = (\n",
    "            f\"initial_kernel={initial_kernel}, \"\n",
    "            f\"dropout={dropout}\"\n",
    "        )\n",
    "        histories_leaky_128.append((label, history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3887a-793c-47cf-b7e0-73a937fc955d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, history in histories:\n",
    "    plt.figure(figsize=(40, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Loss '+label)\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss '+label)\n",
    "    plt.legend()\n",
    "    plt.title(\"Loss over Epochs\")\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title(\"Accuracy over Epochs\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5419f0-c510-41ee-b2da-e778bd421a60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d3a80e-6bce-444f-a478-2ec589849446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
